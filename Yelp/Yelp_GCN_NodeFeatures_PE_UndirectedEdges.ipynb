{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43aec689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.utils as utils\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.nn import GINConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch_geometric as tg\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse as sp\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8122e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePosEncodings_rswe(edge_index, num_nodes):\n",
    "    edge_index = edge_index.t().tolist()\n",
    "    edges = [(src, dst) for src, dst in edge_index]\n",
    "    rows, cols = zip(*edges)\n",
    "    data = np.ones(len(rows))\n",
    "    A = csr_matrix((data, (rows, cols)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "    in_degrees_dict = {node: 0 for node in range(num_nodes)}\n",
    "    # Calculate the in-degrees for each node\n",
    "    for edge in edges:\n",
    "        _, dst = edge\n",
    "        in_degrees_dict[dst] += 1\n",
    "\n",
    "    in_degrees = np.array([in_degrees_dict[i] for i in range(len(in_degrees_dict))], dtype=float)\n",
    "    in_degrees = in_degrees.clip(1)  # Clip to ensure no division by zero\n",
    "    in_degrees = np.power(in_degrees, -1)  # Take the element-wise inverse square root\n",
    "\n",
    "    Dinv = sp.diags(in_degrees, dtype=float)\n",
    "\n",
    "    RW = A * Dinv  \n",
    "    M = RW\n",
    "    \n",
    "    # das ist wieder ein Hyperparameter; sollte >1 sein weil eins immer 0 ist irgendwie!\n",
    "    pos_enc_dim = 5\n",
    "\n",
    "    nb_pos_enc = pos_enc_dim\n",
    "    PE = [torch.from_numpy(M.diagonal()).float()]\n",
    "    M_power = M\n",
    "    for _ in range(nb_pos_enc-1):\n",
    "        M_power = M_power * M\n",
    "        PE.append(torch.from_numpy(M_power.diagonal()).float())\n",
    "    PE = torch.stack(PE,dim=-1)\n",
    "\n",
    "    #ERGEBNIS\n",
    "    RESULT_POS_ENCODING = PE \n",
    "    return RESULT_POS_ENCODING\n",
    "\n",
    "def calculatePosEncodings(edge_index, num_nodes):\n",
    "    print(\"checkpoint1\")\n",
    "    edge_index = edge_index.t().tolist()\n",
    "    edges = [(src, dst) for src, dst in edge_index]\n",
    "\n",
    "    # Create the adjacency matrix in CSR format -> das wird dann fÃ¼r die encodings benutzt!\n",
    "    rows, cols = zip(*edges)\n",
    "    data = np.ones(len(rows))\n",
    "    A = csr_matrix((data, (rows, cols)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "    ''' this code computes the in_degrees matrix from the edge list. it can later be adapted to compute the in-degrees matrix from the adjacency matrix (however, then, we should\n",
    "    do some tests with small sample graphs to ensure everytheing is correct\n",
    "    '''\n",
    "    in_degrees_dict = {node: 0 for node in range(num_nodes)}\n",
    "    # Calculate the in-degrees for each node\n",
    "    for edge in edges:\n",
    "        print(\"checkpoint2\")\n",
    "        _, dst = edge\n",
    "        in_degrees_dict[dst] += 1\n",
    "\n",
    "    in_degrees = np.array([in_degrees_dict[i] for i in range(len(in_degrees_dict))], dtype=float)\n",
    "    in_degrees = in_degrees.clip(1)  # Clip to ensure no division by zero\n",
    "    in_degrees = np.power(in_degrees, -0.5)  # Take the element-wise inverse square root\n",
    "    print(\"checkpoint3\")\n",
    "    # Create the sparse diagonal matrix N\n",
    "    N = sp.diags(in_degrees, dtype=float)\n",
    "\n",
    "    L = sp.eye(num_nodes) - N * A * N\n",
    "\n",
    "    #calc eigvals and eigVecs, equivalent to the original code\n",
    "    EigVal, EigVec = np.linalg.eig(L.toarray())\n",
    "    idx = EigVal.argsort() # increasing order\n",
    "    EigVal, EigVec = EigVal[idx], np.real(EigVec[:,idx])\n",
    "\n",
    "    #pos_enc_dim = hyperparameter!\n",
    "    pos_enc_dim = 5\n",
    "    RESULT_POS_ENCODING = torch.from_numpy(EigVec[:,1:pos_enc_dim+1]).float() \n",
    "    return RESULT_POS_ENCODING\n",
    "\n",
    "def calculateLoss(task_loss, batch, num_nodes, positional_encoding):\n",
    "    #HYPERPARAMETERS\n",
    "    device = \"cpu\"\n",
    "    pos_enc_dim = 1\n",
    "    alpha_loss: 1e-3\n",
    "    lambda_loss: 100  # ist auch 100\n",
    "\n",
    "    #edge_index im korrekten Format definieren\n",
    "    edge_index = batch.edge_index.t().tolist()\n",
    "    edge_index = [(src, dst) for src, dst in edge_index]\n",
    "\n",
    "    # Loss B: Laplacian Eigenvector Loss --------------------------------------------\n",
    "    n = num_nodes\n",
    "\n",
    "    # Laplacian \n",
    "    rows, cols = zip(*edge_index)\n",
    "    data = np.ones(len(rows))\n",
    "    A = csr_matrix((data, (rows, cols)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "    ''' this code computes the in_degrees matrix from the edge list. it can later be adapted to compute the in-degrees matrix from the adjacency matrix (however, then, we should\n",
    "    do some tests with small sample graphs to ensure everything is correct'''\n",
    "\n",
    "    in_degrees_dict = {node: 0 for node in range(num_nodes)}\n",
    "    # Calculate the in-degrees for each node\n",
    "    for edge in edge_index:\n",
    "        _, dst = edge\n",
    "        in_degrees_dict[dst] += 1\n",
    "\n",
    "    in_degrees = np.array([in_degrees_dict[i] for i in range(len(in_degrees_dict))], dtype=float)\n",
    "    in_degrees = in_degrees.clip(1)  # Clip to ensure no division by zero\n",
    "    in_degrees = np.power(in_degrees, -0.5)  # Take the element-wise inverse square root\n",
    "\n",
    "    # Create the sparse diagonal matrix N\n",
    "    N = sp.diags(in_degrees, dtype=float)\n",
    "    L = sp.eye(num_nodes) - N * A * N\n",
    "\n",
    "    p = positional_encoding\n",
    "    pT = torch.transpose(p, 1, 0)\n",
    "    loss_b_1 = torch.trace(torch.mm(torch.mm(pT, torch.Tensor(L.todense()).to(device)), p))\n",
    "\n",
    "    '''  TODO: loss_b_2 \n",
    "    '''\n",
    "\n",
    "    loss_b = loss_b_1\n",
    "\n",
    "    #TODO: parameter tunen!\n",
    "    loss = task_loss + 1e-3* loss_b\n",
    "    return loss\n",
    "\n",
    "\n",
    "def precision(predictions, targets, threshold):\n",
    "    # Apply a threshold to the predictions\n",
    "    binary_predictions = (predictions >= threshold).astype(int)\n",
    "    binary_targets = (targets >= threshold).astype(int)\n",
    "\n",
    "    # Calculate the true positive (TP) and false positive (FP) counts\n",
    "    TP = np.sum((binary_predictions == 1) & (binary_targets == 1))\n",
    "    FP = np.sum((binary_predictions == 1) & (binary_targets == 0))\n",
    "\n",
    "    print(\"Negative: \")\n",
    "    print(np.sum(binary_targets == 1))\n",
    "    print(\"Positive: \")\n",
    "    print(np.sum(binary_targets == 0))\n",
    "    # Calculate precision\n",
    "    precision_value = TP / (TP + FP)\n",
    "    return precision_value\n",
    "\n",
    "def recall(predictions, targets, threshold):\n",
    "    # Apply a threshold to the predictions\n",
    "    binary_predictions = (predictions >= threshold).astype(int)\n",
    "    binary_targets = (targets >= threshold).astype(int)\n",
    "    # Calculate the true positive (TP) and false negative (FN) counts\n",
    "    TP = np.sum((binary_predictions == 1) & (binary_targets == 1))\n",
    "    FN = np.sum((binary_predictions == 0) & (binary_targets == 1))\n",
    "    # Calculate recall\n",
    "    recall_value = TP / (TP + FN)\n",
    "    return recall_value\n",
    "\n",
    "def precission_recall_at_k (predictions, targets, threshold, k):\n",
    "    # Combine ratings and predictions into tuples for sorting\n",
    "    combined = list(zip(targets, predictions))\n",
    "\n",
    "    # Sort the combined list in descending order of predictions\n",
    "    combined.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract top k sorted items and calculate precision and recall\n",
    "    top_k_items = combined[:k]\n",
    "    true_positives = sum(1 for rating, _ in top_k_items if rating >= threshold)\n",
    "    false_positives = k - true_positives\n",
    "    relevant_items = sum(1 for rating in targets if rating >= threshold)\n",
    "    false_negatives = relevant_items - true_positives\n",
    "\n",
    "    precision_at_k = true_positives / (true_positives + false_positives)\n",
    "    recall_at_k = true_positives / (true_positives + false_negatives)\n",
    "    normalized_recall_at_k = recall_at_k / (k / relevant_items)\n",
    "\n",
    "\n",
    "    return precision_at_k, recall_at_k, normalized_recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4d17e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done business\n",
      "done reviews\n",
      "done users\n"
     ]
    }
   ],
   "source": [
    "# Reading in all the data\n",
    "\n",
    "business_ids=[]\n",
    "business_average_stars=[]\n",
    "business_review_count=[]\n",
    "\n",
    "try:\n",
    "    with open('yelp_dataset/yelp_academic_dataset_business.json', 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                business_ids.append(data[\"business_id\"])\n",
    "                business_average_stars.append(data[\"stars\"])\n",
    "                business_review_count.append(data[\"review_count\"])\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "print(\"done business\")\n",
    "\n",
    "review_ids=[]\n",
    "review_business_ids=[]\n",
    "review_user_ids=[]\n",
    "review_stars=[]\n",
    "\n",
    "try:\n",
    "    with open('yelp_dataset/yelp_academic_dataset_review.json', 'r', encoding='utf-8') as json_file:\n",
    "        for i,line in enumerate(json_file):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                review_ids.append(data[\"review_id\"])\n",
    "                review_business_ids.append(data[\"business_id\"])\n",
    "                review_user_ids.append(data[\"user_id\"])\n",
    "                review_stars.append(data[\"stars\"])\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "print(\"done reviews\")\n",
    "\n",
    "user_ids=[]\n",
    "\n",
    "try:\n",
    "    with open('yelp_dataset/yelp_academic_dataset_user.json', 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                user_ids.append(data[\"user_id\"])\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "print(\"done users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618b183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987897\n",
      "150346\n",
      "6990280\n",
      "---------------------------------------------\n",
      "20000\n",
      "10000\n",
      "6990280\n"
     ]
    }
   ],
   "source": [
    "# As there is too much data use a subset by manipulating the business and user sets\n",
    "\n",
    "print(len(user_ids))\n",
    "print(len(business_ids))\n",
    "print(len(review_stars))\n",
    "\n",
    "businesses = 10000\n",
    "users = 20000\n",
    "\n",
    "business_average_stars = business_average_stars[:businesses]\n",
    "business_review_count = business_review_count[:businesses]\n",
    "business_ids = business_ids[:businesses]\n",
    "\n",
    "user_ids = user_ids[:users]\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "print(len(user_ids))\n",
    "print(len(business_ids))\n",
    "print(len(review_stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed791a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47703\n"
     ]
    }
   ],
   "source": [
    "# User and business to index mapping in order.\n",
    "# Review lists are adjusted to only include users and businesses from the subset lists.\n",
    "\n",
    "user_to_index = {user_id: index for index, user_id in enumerate(set(user_ids))}\n",
    "business_to_index = {business_id: index for index, business_id in enumerate(set(business_ids))}\n",
    "\n",
    "\n",
    "user_index_col = [user_to_index[user_id] for user_id in user_ids]\n",
    "business_index_col = [business_to_index[business_id] for business_id in business_ids]\n",
    "\n",
    "skip_indexes = []\n",
    "current_index = -1\n",
    "\n",
    "for user_id in review_user_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        tmp = user_to_index[user_id]\n",
    "    except KeyError:\n",
    "        skip_indexes.append(current_index)\n",
    "\n",
    "current_index = -1\n",
    "for business_id in review_business_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        tmp = business_to_index[business_id]\n",
    "    except KeyError:\n",
    "        skip_indexes.append(current_index)    \n",
    "\n",
    "skip_indexes = set(skip_indexes)\n",
    "print(6990280 - len(skip_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d50b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22403\n",
      "30000\n",
      "Number of Users in index col 16327\n",
      "Number of businesses in index col 6076\n",
      "Total reviews left 47703\n",
      "22403\n"
     ]
    }
   ],
   "source": [
    "current_index = -1\n",
    "\n",
    "review_user_index_col = []\n",
    "for user_id in review_user_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        if current_index in skip_indexes:\n",
    "            pass\n",
    "        else:\n",
    "            user_index = user_to_index[user_id]\n",
    "            review_user_index_col.append(businesses+user_index)\n",
    "    except KeyError:\n",
    "        print(\"Huh?\")        \n",
    "        \n",
    "current_index = -1        \n",
    "review_business_index_col = []\n",
    "for business_id in review_business_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        if current_index in skip_indexes:\n",
    "            pass\n",
    "        else:\n",
    "            business_index = business_to_index[business_id]\n",
    "            review_business_index_col.append(business_index)\n",
    "    except KeyError:\n",
    "        print(\"Huh?\")\n",
    "    \n",
    "current_index = -1\n",
    "adjusted_review_stars = []\n",
    "for star in review_stars:\n",
    "        current_index = current_index + 1\n",
    "        if current_index in skip_indexes:\n",
    "            pass\n",
    "        else:\n",
    "            adjusted_review_stars.append(star)\n",
    "\n",
    "num_nodes = len(set(review_user_index_col)) + len(set(review_business_index_col)) \n",
    "print(num_nodes)\n",
    "print(len(user_to_index)+len(business_to_index))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of Users in index col \" + str(len(set(review_user_index_col))))\n",
    "print(\"Number of businesses in index col \" + str(len(set(review_business_index_col))))\n",
    "print(\"Total reviews left \" + str(len(adjusted_review_stars)))\n",
    "print(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f84a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4554\n",
      "tensor([[5.0000e+00, 1.5371e-03],\n",
      "        [3.0000e+00, 3.2938e-03],\n",
      "        [3.5000e+00, 4.8309e-03],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Feature list including average stars and the review_count/max_review_count of a business.\n",
    "# Also a dummy padding is added for the users.\n",
    "\n",
    "adjusted_features = []\n",
    "\n",
    "for starts in business_average_stars:\n",
    "    adjusted_features.append([starts])\n",
    "    \n",
    "highest_review_count = 0\n",
    "for review in business_review_count:\n",
    "    if(review > highest_review_count):\n",
    "        highest_review_count = review\n",
    "print(highest_review_count)\n",
    "        \n",
    "for i in range(len(business_review_count)):\n",
    "    adjusted_features[i].append(business_review_count[i]/highest_review_count)\n",
    "\n",
    "adjusted_features_tensor = torch.tensor(adjusted_features)\n",
    "\n",
    "num_features = len(adjusted_features[0])\n",
    "\n",
    "num_users = len(set(user_ids))\n",
    "user_genre_features = torch.zeros(num_users,num_features)\n",
    "\n",
    "features = torch.cat((adjusted_features_tensor, user_genre_features), dim=0)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a582bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11512, 20461, 14585,  ...,  8439,  8453,  5276],\n",
      "        [ 7949,  6242,  9511,  ..., 19175, 13934, 13383]])\n"
     ]
    }
   ],
   "source": [
    "adjusted_review_stars_ud = adjusted_review_stars + adjusted_review_stars\n",
    "review_user_index_col_ud = review_user_index_col + review_business_index_col\n",
    "review_business_index_col_ud = review_business_index_col + review_user_index_col\n",
    "\n",
    "rating_tensor = torch.tensor(adjusted_review_stars_ud, dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([review_user_index_col_ud, review_business_index_col_ud], dtype=torch.long)\n",
    "\n",
    "positional_encodings = calculatePosEncodings_rswe(edge_index, 30000)\n",
    "\n",
    "#TODO: num nodes 30.000 oder num_nodes?\n",
    "data = Data(edge_index=edge_index, x=features, y=rating_tensor, positional_encodings=positional_encodings)\n",
    "\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f393a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN_nopos(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(7, hidden_channels)\n",
    "        self.conv1_nopos = GCNConv(2, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2_var2 = GCNConv(hidden_channels*2, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        #hidden channels funktioniert besser!\n",
    "        self.conv3_nopos = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "\n",
    "        #this is for learning of the positional encodings, which is seperate!!!\n",
    "        self.conv1_pos = GCNConv(5, hidden_channels)\n",
    "        self.conv2_pos = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3_pos = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index, pos_embeddings):\n",
    "        x = x.view(-1, x.size(2))\n",
    "        #fh from the paper\n",
    "        x = self.conv1_nopos(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_nopos(x, edge_index)\n",
    "\n",
    "        movie_embed = x[edge_index[1]]\n",
    "        \n",
    "        ratings = torch.sum(movie_embed, dim=1)\n",
    "\n",
    "        return ratings\n",
    "\n",
    "\n",
    "class GCN_var1(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # number of in layers = number of node features + number of positional embedding dimensions\n",
    "        # TODO: ADAPT WHEN ADDING FEATURES OR EMBEDDING DIMENSIONS!!!!\n",
    "        self.conv1 = GCNConv(7, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        #this is for learning of the positional encodings, which is seperate!!!\n",
    "        self.conv1_pos = GCNConv(5, hidden_channels)\n",
    "        self.conv2_pos = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3_pos = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, pos_embeddings):\n",
    "        x = x.view(-1, x.size(2))\n",
    "        pos_embeddings = pos_embeddings.view(-1, pos_embeddings.size(2))\n",
    "        x = torch.cat([x, pos_embeddings], dim=1)\n",
    "\n",
    "        #fh from the paper\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        #Now the learning of positional embeddings. So this is fp from the paper\n",
    "        pos_embeddings = self.conv1_pos(pos_embeddings, edge_index)\n",
    "        pos_embeddings = F.relu(pos_embeddings)\n",
    "        pos_embeddings = self.conv2_pos(pos_embeddings, edge_index)\n",
    "        pos_embeddings = F.relu(pos_embeddings)\n",
    "        pos_embeddings = self.conv3_pos(pos_embeddings, edge_index)\n",
    "\n",
    "        final_output = self.linear(torch.cat([x, pos_embeddings]))\n",
    "\n",
    "        movie_embed = final_output[edge_index[1]]            \n",
    "        ratings = torch.sum(movie_embed, dim=1)\n",
    "        return ratings\n",
    "\n",
    "\n",
    "class GCN_variant2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # number of in layers = number of node features + number of positional embedding dimensions\n",
    "        # TODO: ADAPT WHEN ADDING FEATURES OR EMBEDDING DIMENSIONS!!!!\n",
    "        self.conv1 = GCNConv(7, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2_var2 = GCNConv(hidden_channels*2, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        #this is for learning of the positional encodings, which is seperate!!!\n",
    "        self.conv1_pos = GCNConv(5, hidden_channels)\n",
    "        self.conv2_pos = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3_pos = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, pos_embeddings):\n",
    "        x = x.view(-1, x.size(2))\n",
    "        pos_embeddings = pos_embeddings.view(-1, pos_embeddings.size(2))\n",
    "        x = torch.cat([x, pos_embeddings], dim=1)\n",
    "\n",
    "        #fh from the paper\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        pos_embeddings = self.conv1_pos(pos_embeddings, edge_index)\n",
    "        pos_embeddings = F.relu(pos_embeddings)\n",
    "        #x = self.conv2(torch.cat([x,pos_embeddings],dim=1), edge_index)\n",
    "        x = self.conv2_var2(torch.cat([x,pos_embeddings],dim=1), edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        movie_embed = x[edge_index[1]]\n",
    "        ratings = torch.sum(movie_embed, dim=1)\n",
    "\n",
    "        return ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95e32818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Training Loss: 25.68608283996582, Validation Loss: 21.37664031982422\n",
      "Epoch 2/300, Training Loss: 20.579904556274414, Validation Loss: 16.96460723876953\n",
      "Epoch 3/300, Training Loss: 16.301538467407227, Validation Loss: 13.262295722961426\n",
      "Epoch 4/300, Training Loss: 12.801722526550293, Validation Loss: 10.28968620300293\n",
      "Epoch 5/300, Training Loss: 10.028038024902344, Validation Loss: 8.106943130493164\n",
      "Epoch 6/300, Training Loss: 7.980322360992432, Validation Loss: 6.6806159019470215\n",
      "Epoch 7/300, Training Loss: 6.663872241973877, Validation Loss: 5.591006278991699\n",
      "Epoch 8/300, Training Loss: 5.590228080749512, Validation Loss: 4.699077606201172\n",
      "Epoch 9/300, Training Loss: 4.742715835571289, Validation Loss: 4.206088066101074\n",
      "Epoch 10/300, Training Loss: 4.331237316131592, Validation Loss: 4.193005561828613\n",
      "Epoch 11/300, Training Loss: 4.408010005950928, Validation Loss: 4.478495121002197\n",
      "Epoch 12/300, Training Loss: 4.774759769439697, Validation Loss: 4.751919746398926\n",
      "Epoch 13/300, Training Loss: 5.10240364074707, Validation Loss: 4.841270446777344\n",
      "Epoch 14/300, Training Loss: 5.21500825881958, Validation Loss: 4.72108268737793\n",
      "Epoch 15/300, Training Loss: 5.090488433837891, Validation Loss: 4.452610969543457\n",
      "Epoch 16/300, Training Loss: 4.796492576599121, Validation Loss: 4.132142543792725\n",
      "Epoch 17/300, Training Loss: 4.430928707122803, Validation Loss: 3.9071457386016846\n",
      "Epoch 18/300, Training Loss: 4.110899925231934, Validation Loss: 3.7386345863342285\n",
      "Epoch 19/300, Training Loss: 3.884646415710449, Validation Loss: 3.6054940223693848\n",
      "Epoch 20/300, Training Loss: 3.7097325325012207, Validation Loss: 3.5060713291168213\n",
      "Epoch 21/300, Training Loss: 3.5791187286376953, Validation Loss: 3.438244342803955\n",
      "Epoch 22/300, Training Loss: 3.4879539012908936, Validation Loss: 3.39471173286438\n",
      "Epoch 23/300, Training Loss: 3.4272446632385254, Validation Loss: 3.366569995880127\n",
      "Epoch 24/300, Training Loss: 3.3864524364471436, Validation Loss: 3.344346761703491\n",
      "Epoch 25/300, Training Loss: 3.355088472366333, Validation Loss: 3.3203816413879395\n",
      "Epoch 26/300, Training Loss: 3.3244893550872803, Validation Loss: 3.289069175720215\n",
      "Epoch 27/300, Training Loss: 3.2885851860046387, Validation Loss: 3.2472352981567383\n",
      "Epoch 28/300, Training Loss: 3.24385666847229, Validation Loss: 3.194002628326416\n",
      "Epoch 29/300, Training Loss: 3.189174175262451, Validation Loss: 3.1303048133850098\n",
      "Epoch 30/300, Training Loss: 3.1252384185791016, Validation Loss: 3.0582356452941895\n",
      "Epoch 31/300, Training Loss: 3.0540823936462402, Validation Loss: 2.9807028770446777\n",
      "Epoch 32/300, Training Loss: 2.9784927368164062, Validation Loss: 2.9009149074554443\n",
      "Epoch 33/300, Training Loss: 2.901557207107544, Validation Loss: 2.82199764251709\n",
      "Epoch 34/300, Training Loss: 2.8262643814086914, Validation Loss: 2.746622323989868\n",
      "Epoch 35/300, Training Loss: 2.755150556564331, Validation Loss: 2.6767683029174805\n",
      "Epoch 36/300, Training Loss: 2.6900384426116943, Validation Loss: 2.6135802268981934\n",
      "Epoch 37/300, Training Loss: 2.631897449493408, Validation Loss: 2.5573229789733887\n",
      "Epoch 38/300, Training Loss: 2.5808069705963135, Validation Loss: 2.507471799850464\n",
      "Epoch 39/300, Training Loss: 2.536041498184204, Validation Loss: 2.46288800239563\n",
      "Epoch 40/300, Training Loss: 2.4962618350982666, Validation Loss: 2.422104835510254\n",
      "Epoch 41/300, Training Loss: 2.459808826446533, Validation Loss: 2.3835935592651367\n",
      "Epoch 42/300, Training Loss: 2.4249870777130127, Validation Loss: 2.346038579940796\n",
      "Epoch 43/300, Training Loss: 2.3903541564941406, Validation Loss: 2.3085193634033203\n",
      "Epoch 44/300, Training Loss: 2.354904890060425, Validation Loss: 2.270592212677002\n",
      "Epoch 45/300, Training Loss: 2.318169355392456, Validation Loss: 2.2322731018066406\n",
      "Epoch 46/300, Training Loss: 2.2801833152770996, Validation Loss: 2.1939313411712646\n",
      "Epoch 47/300, Training Loss: 2.2413761615753174, Validation Loss: 2.1561317443847656\n",
      "Epoch 48/300, Training Loss: 2.202415704727173, Validation Loss: 2.1194841861724854\n",
      "Epoch 49/300, Training Loss: 2.1640329360961914, Validation Loss: 2.0845022201538086\n",
      "Epoch 50/300, Training Loss: 2.1268832683563232, Validation Loss: 2.0515239238739014\n",
      "Epoch 51/300, Training Loss: 2.091463804244995, Validation Loss: 2.0206820964813232\n",
      "Epoch 52/300, Training Loss: 2.0580379962921143, Validation Loss: 1.9919127225875854\n",
      "Epoch 53/300, Training Loss: 2.0266664028167725, Validation Loss: 1.9649981260299683\n",
      "Epoch 54/300, Training Loss: 1.9972397089004517, Validation Loss: 1.9396237134933472\n",
      "Epoch 55/300, Training Loss: 1.9695663452148438, Validation Loss: 1.9154361486434937\n",
      "Epoch 56/300, Training Loss: 1.9433283805847168, Validation Loss: 1.89210045337677\n",
      "Epoch 57/300, Training Loss: 1.9182209968566895, Validation Loss: 1.8693331480026245\n",
      "Epoch 58/300, Training Loss: 1.8939820528030396, Validation Loss: 1.8469282388687134\n",
      "Epoch 59/300, Training Loss: 1.8704161643981934, Validation Loss: 1.8247605562210083\n",
      "Epoch 60/300, Training Loss: 1.8473992347717285, Validation Loss: 1.8027855157852173\n",
      "Epoch 61/300, Training Loss: 1.8248711824417114, Validation Loss: 1.7810262441635132\n",
      "Epoch 62/300, Training Loss: 1.8028236627578735, Validation Loss: 1.7595537900924683\n",
      "Epoch 63/300, Training Loss: 1.7812960147857666, Validation Loss: 1.7384510040283203\n",
      "Epoch 64/300, Training Loss: 1.760361671447754, Validation Loss: 1.7178359031677246\n",
      "Epoch 65/300, Training Loss: 1.7400951385498047, Validation Loss: 1.6978439092636108\n",
      "Epoch 66/300, Training Loss: 1.7205500602722168, Validation Loss: 1.6785669326782227\n",
      "Epoch 67/300, Training Loss: 1.7017768621444702, Validation Loss: 1.6600724458694458\n",
      "Epoch 68/300, Training Loss: 1.683800458908081, Validation Loss: 1.6424003839492798\n",
      "Epoch 69/300, Training Loss: 1.666622519493103, Validation Loss: 1.6255621910095215\n",
      "Epoch 70/300, Training Loss: 1.6502223014831543, Validation Loss: 1.60954749584198\n",
      "Epoch 71/300, Training Loss: 1.6345593929290771, Validation Loss: 1.5943260192871094\n",
      "Epoch 72/300, Training Loss: 1.6195813417434692, Validation Loss: 1.5798556804656982\n",
      "Epoch 73/300, Training Loss: 1.6052292585372925, Validation Loss: 1.566088080406189\n",
      "Epoch 74/300, Training Loss: 1.5914453268051147, Validation Loss: 1.5529747009277344\n",
      "Epoch 75/300, Training Loss: 1.5781772136688232, Validation Loss: 1.5404691696166992\n",
      "Epoch 76/300, Training Loss: 1.565380573272705, Validation Loss: 1.5285310745239258\n",
      "Epoch 77/300, Training Loss: 1.5530216693878174, Validation Loss: 1.5171256065368652\n",
      "Epoch 78/300, Training Loss: 1.541077971458435, Validation Loss: 1.5062247514724731\n",
      "Epoch 79/300, Training Loss: 1.529534935951233, Validation Loss: 1.4958045482635498\n",
      "Epoch 80/300, Training Loss: 1.5183863639831543, Validation Loss: 1.485844612121582\n",
      "Epoch 81/300, Training Loss: 1.5076305866241455, Validation Loss: 1.4763261079788208\n",
      "Epoch 82/300, Training Loss: 1.4972671270370483, Validation Loss: 1.4672309160232544\n",
      "Epoch 83/300, Training Loss: 1.4872967004776, Validation Loss: 1.458539366722107\n",
      "Epoch 84/300, Training Loss: 1.477717399597168, Validation Loss: 1.4502320289611816\n",
      "Epoch 85/300, Training Loss: 1.4685250520706177, Validation Loss: 1.4422870874404907\n",
      "Epoch 86/300, Training Loss: 1.4597127437591553, Validation Loss: 1.434683084487915\n",
      "Epoch 87/300, Training Loss: 1.4512706995010376, Validation Loss: 1.4273977279663086\n",
      "Epoch 88/300, Training Loss: 1.443186640739441, Validation Loss: 1.4204095602035522\n",
      "Epoch 89/300, Training Loss: 1.4354461431503296, Validation Loss: 1.413698434829712\n",
      "Epoch 90/300, Training Loss: 1.428034782409668, Validation Loss: 1.4072456359863281\n",
      "Epoch 91/300, Training Loss: 1.4209365844726562, Validation Loss: 1.401034951210022\n",
      "Epoch 92/300, Training Loss: 1.4141377210617065, Validation Loss: 1.3950525522232056\n",
      "Epoch 93/300, Training Loss: 1.4076236486434937, Validation Loss: 1.389286756515503\n",
      "Epoch 94/300, Training Loss: 1.401381492614746, Validation Loss: 1.3837289810180664\n",
      "Epoch 95/300, Training Loss: 1.395399808883667, Validation Loss: 1.3783719539642334\n",
      "Epoch 96/300, Training Loss: 1.3896682262420654, Validation Loss: 1.3732104301452637\n",
      "Epoch 97/300, Training Loss: 1.3841770887374878, Validation Loss: 1.3682403564453125\n",
      "Epoch 98/300, Training Loss: 1.378918170928955, Validation Loss: 1.3634589910507202\n",
      "Epoch 99/300, Training Loss: 1.3738833665847778, Validation Loss: 1.358863115310669\n",
      "Epoch 100/300, Training Loss: 1.3690654039382935, Validation Loss: 1.3544508218765259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/300, Training Loss: 1.3644566535949707, Validation Loss: 1.3502192497253418\n",
      "Epoch 102/300, Training Loss: 1.3600504398345947, Validation Loss: 1.346165657043457\n",
      "Epoch 103/300, Training Loss: 1.3558392524719238, Validation Loss: 1.3422868251800537\n",
      "Epoch 104/300, Training Loss: 1.3518155813217163, Validation Loss: 1.338578701019287\n",
      "Epoch 105/300, Training Loss: 1.3479726314544678, Validation Loss: 1.3350372314453125\n",
      "Epoch 106/300, Training Loss: 1.3443025350570679, Validation Loss: 1.3316576480865479\n",
      "Epoch 107/300, Training Loss: 1.3407979011535645, Validation Loss: 1.3284345865249634\n",
      "Epoch 108/300, Training Loss: 1.3374518156051636, Validation Loss: 1.3253626823425293\n",
      "Epoch 109/300, Training Loss: 1.334256887435913, Validation Loss: 1.3224363327026367\n",
      "Epoch 110/300, Training Loss: 1.3312063217163086, Validation Loss: 1.3196496963500977\n",
      "Epoch 111/300, Training Loss: 1.3282933235168457, Validation Loss: 1.316996693611145\n",
      "Epoch 112/300, Training Loss: 1.3255119323730469, Validation Loss: 1.31447172164917\n",
      "Epoch 113/300, Training Loss: 1.322856068611145, Validation Loss: 1.3120688199996948\n",
      "Epoch 114/300, Training Loss: 1.3203195333480835, Validation Loss: 1.3097821474075317\n",
      "Epoch 115/300, Training Loss: 1.317898154258728, Validation Loss: 1.3076063394546509\n",
      "Epoch 116/300, Training Loss: 1.3155862092971802, Validation Loss: 1.3055360317230225\n",
      "Epoch 117/300, Training Loss: 1.313379168510437, Validation Loss: 1.3035656213760376\n",
      "Epoch 118/300, Training Loss: 1.3112728595733643, Validation Loss: 1.3016905784606934\n",
      "Epoch 119/300, Training Loss: 1.309262752532959, Validation Loss: 1.2999050617218018\n",
      "Epoch 120/300, Training Loss: 1.307344913482666, Validation Loss: 1.2982051372528076\n",
      "Epoch 121/300, Training Loss: 1.3055156469345093, Validation Loss: 1.2965857982635498\n",
      "Epoch 122/300, Training Loss: 1.3037712574005127, Validation Loss: 1.2950429916381836\n",
      "Epoch 123/300, Training Loss: 1.3021081686019897, Validation Loss: 1.2935725450515747\n",
      "Epoch 124/300, Training Loss: 1.3005225658416748, Validation Loss: 1.2921704053878784\n",
      "Epoch 125/300, Training Loss: 1.2990117073059082, Validation Loss: 1.290832757949829\n",
      "Epoch 126/300, Training Loss: 1.2975717782974243, Validation Loss: 1.2895560264587402\n",
      "Epoch 127/300, Training Loss: 1.2961997985839844, Validation Loss: 1.2883373498916626\n",
      "Epoch 128/300, Training Loss: 1.2948927879333496, Validation Loss: 1.2871733903884888\n",
      "Epoch 129/300, Training Loss: 1.2936478853225708, Validation Loss: 1.2860609292984009\n",
      "Epoch 130/300, Training Loss: 1.2924622297286987, Validation Loss: 1.2849980592727661\n",
      "Epoch 131/300, Training Loss: 1.2913329601287842, Validation Loss: 1.2839820384979248\n",
      "Epoch 132/300, Training Loss: 1.290257453918457, Validation Loss: 1.283010482788086\n",
      "Epoch 133/300, Training Loss: 1.2892334461212158, Validation Loss: 1.282081127166748\n",
      "Epoch 134/300, Training Loss: 1.2882585525512695, Validation Loss: 1.2811927795410156\n",
      "Epoch 135/300, Training Loss: 1.2873303890228271, Validation Loss: 1.2803434133529663\n",
      "Epoch 136/300, Training Loss: 1.2864468097686768, Validation Loss: 1.2795311212539673\n",
      "Epoch 137/300, Training Loss: 1.2856059074401855, Validation Loss: 1.278754472732544\n",
      "Epoch 138/300, Training Loss: 1.2848057746887207, Validation Loss: 1.2780123949050903\n",
      "Epoch 139/300, Training Loss: 1.2840441465377808, Validation Loss: 1.2773033380508423\n",
      "Epoch 140/300, Training Loss: 1.2833197116851807, Validation Loss: 1.2766261100769043\n",
      "Epoch 141/300, Training Loss: 1.2826303243637085, Validation Loss: 1.2759793996810913\n",
      "Epoch 142/300, Training Loss: 1.2819746732711792, Validation Loss: 1.275362491607666\n",
      "Epoch 143/300, Training Loss: 1.2813513278961182, Validation Loss: 1.2747739553451538\n",
      "Epoch 144/300, Training Loss: 1.280758261680603, Validation Loss: 1.2742127180099487\n",
      "Epoch 145/300, Training Loss: 1.2801944017410278, Validation Loss: 1.2736778259277344\n",
      "Epoch 146/300, Training Loss: 1.279658317565918, Validation Loss: 1.2731685638427734\n",
      "Epoch 147/300, Training Loss: 1.279148817062378, Validation Loss: 1.2726833820343018\n",
      "Epoch 148/300, Training Loss: 1.2786643505096436, Validation Loss: 1.2722214460372925\n",
      "Epoch 149/300, Training Loss: 1.2782042026519775, Validation Loss: 1.271782398223877\n",
      "Epoch 150/300, Training Loss: 1.2777667045593262, Validation Loss: 1.271364450454712\n",
      "Epoch 151/300, Training Loss: 1.2773510217666626, Validation Loss: 1.2709673643112183\n",
      "Epoch 152/300, Training Loss: 1.2769559621810913, Validation Loss: 1.2705897092819214\n",
      "Epoch 153/300, Training Loss: 1.2765809297561646, Validation Loss: 1.270231008529663\n",
      "Epoch 154/300, Training Loss: 1.2762246131896973, Validation Loss: 1.2698901891708374\n",
      "Epoch 155/300, Training Loss: 1.2758862972259521, Validation Loss: 1.2695661783218384\n",
      "Epoch 156/300, Training Loss: 1.2755649089813232, Validation Loss: 1.2692584991455078\n",
      "Epoch 157/300, Training Loss: 1.2752597332000732, Validation Loss: 1.2689663171768188\n",
      "Epoch 158/300, Training Loss: 1.2749701738357544, Validation Loss: 1.268688678741455\n",
      "Epoch 159/300, Training Loss: 1.2746953964233398, Validation Loss: 1.2684248685836792\n",
      "Epoch 160/300, Training Loss: 1.2744344472885132, Validation Loss: 1.268174409866333\n",
      "Epoch 161/300, Training Loss: 1.2741868495941162, Validation Loss: 1.2679359912872314\n",
      "Epoch 162/300, Training Loss: 1.2739520072937012, Validation Loss: 1.2677096128463745\n",
      "Epoch 163/300, Training Loss: 1.273728609085083, Validation Loss: 1.2674907445907593\n",
      "Epoch 164/300, Training Loss: 1.2735083103179932, Validation Loss: 1.2672663927078247\n",
      "Epoch 165/300, Training Loss: 1.273262619972229, Validation Loss: 1.2669991254806519\n",
      "Epoch 166/300, Training Loss: 1.2733116149902344, Validation Loss: 1.2668370008468628\n",
      "Epoch 167/300, Training Loss: 1.2728744745254517, Validation Loss: 1.2667628526687622\n",
      "Epoch 168/300, Training Loss: 1.2727649211883545, Validation Loss: 1.2666118144989014\n",
      "Epoch 169/300, Training Loss: 1.2726151943206787, Validation Loss: 1.266463041305542\n",
      "Epoch 170/300, Training Loss: 1.2724623680114746, Validation Loss: 1.2663191556930542\n",
      "Epoch 171/300, Training Loss: 1.2723175287246704, Validation Loss: 1.2661795616149902\n",
      "Epoch 172/300, Training Loss: 1.272180438041687, Validation Loss: 1.2660441398620605\n",
      "Epoch 173/300, Training Loss: 1.272050380706787, Validation Loss: 1.2659128904342651\n",
      "Epoch 174/300, Training Loss: 1.2719272375106812, Validation Loss: 1.2657853364944458\n",
      "Epoch 175/300, Training Loss: 1.2718106508255005, Validation Loss: 1.2656618356704712\n",
      "Epoch 176/300, Training Loss: 1.2717000246047974, Validation Loss: 1.2655422687530518\n",
      "Epoch 177/300, Training Loss: 1.2715957164764404, Validation Loss: 1.2654262781143188\n",
      "Epoch 178/300, Training Loss: 1.2714967727661133, Validation Loss: 1.2653146982192993\n",
      "Epoch 179/300, Training Loss: 1.271403193473816, Validation Loss: 1.2652068138122559\n",
      "Epoch 180/300, Training Loss: 1.2713147401809692, Validation Loss: 1.2651033401489258\n",
      "Epoch 181/300, Training Loss: 1.2712310552597046, Validation Loss: 1.2650039196014404\n",
      "Epoch 182/300, Training Loss: 1.2711520195007324, Validation Loss: 1.264909267425537\n",
      "Epoch 183/300, Training Loss: 1.2710775136947632, Validation Loss: 1.2648186683654785\n",
      "Epoch 184/300, Training Loss: 1.2710069417953491, Validation Loss: 1.2647325992584229\n",
      "Epoch 185/300, Training Loss: 1.2709404230117798, Validation Loss: 1.264650821685791\n",
      "Epoch 186/300, Training Loss: 1.2708775997161865, Validation Loss: 1.264573574066162\n",
      "Epoch 187/300, Training Loss: 1.2708182334899902, Validation Loss: 1.264500617980957\n",
      "Epoch 188/300, Training Loss: 1.2707624435424805, Validation Loss: 1.2644318342208862\n",
      "Epoch 189/300, Training Loss: 1.27070951461792, Validation Loss: 1.2643672227859497\n",
      "Epoch 190/300, Training Loss: 1.2706596851348877, Validation Loss: 1.2643067836761475\n",
      "Epoch 191/300, Training Loss: 1.2706125974655151, Validation Loss: 1.2642501592636108\n",
      "Epoch 192/300, Training Loss: 1.2705684900283813, Validation Loss: 1.2641972303390503\n",
      "Epoch 193/300, Training Loss: 1.2705265283584595, Validation Loss: 1.2641477584838867\n",
      "Epoch 194/300, Training Loss: 1.2704871892929077, Validation Loss: 1.264101505279541\n",
      "Epoch 195/300, Training Loss: 1.2704499959945679, Validation Loss: 1.264058232307434\n",
      "Epoch 196/300, Training Loss: 1.2704150676727295, Validation Loss: 1.2640180587768555\n",
      "Epoch 197/300, Training Loss: 1.2703824043273926, Validation Loss: 1.2639803886413574\n",
      "Epoch 198/300, Training Loss: 1.270351529121399, Validation Loss: 1.2639451026916504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/300, Training Loss: 1.2703224420547485, Validation Loss: 1.2639116048812866\n",
      "Epoch 200/300, Training Loss: 1.2702950239181519, Validation Loss: 1.2638802528381348\n",
      "Epoch 201/300, Training Loss: 1.2702692747116089, Validation Loss: 1.2638509273529053\n",
      "Epoch 202/300, Training Loss: 1.2702451944351196, Validation Loss: 1.2638227939605713\n",
      "Epoch 203/300, Training Loss: 1.270222544670105, Validation Loss: 1.263796091079712\n",
      "Epoch 204/300, Training Loss: 1.2702009677886963, Validation Loss: 1.2637698650360107\n",
      "Epoch 205/300, Training Loss: 1.2701809406280518, Validation Loss: 1.2637447118759155\n",
      "Epoch 206/300, Training Loss: 1.2701621055603027, Validation Loss: 1.2637206315994263\n",
      "Epoch 207/300, Training Loss: 1.2701443433761597, Validation Loss: 1.263697624206543\n",
      "Epoch 208/300, Training Loss: 1.270127773284912, Validation Loss: 1.2636752128601074\n",
      "Epoch 209/300, Training Loss: 1.2701125144958496, Validation Loss: 1.263654112815857\n",
      "Epoch 210/300, Training Loss: 1.2700986862182617, Validation Loss: 1.263633370399475\n",
      "Epoch 211/300, Training Loss: 1.2700858116149902, Validation Loss: 1.2636131048202515\n",
      "Epoch 212/300, Training Loss: 1.2700737714767456, Validation Loss: 1.263593077659607\n",
      "Epoch 213/300, Training Loss: 1.270062804222107, Validation Loss: 1.2635735273361206\n",
      "Epoch 214/300, Training Loss: 1.2700520753860474, Validation Loss: 1.263554334640503\n",
      "Epoch 215/300, Training Loss: 1.2700423002243042, Validation Loss: 1.2635356187820435\n",
      "Epoch 216/300, Training Loss: 1.2700331211090088, Validation Loss: 1.2635174989700317\n",
      "Epoch 217/300, Training Loss: 1.2700246572494507, Validation Loss: 1.26349937915802\n",
      "Epoch 218/300, Training Loss: 1.2700167894363403, Validation Loss: 1.2634822130203247\n",
      "Epoch 219/300, Training Loss: 1.2700092792510986, Validation Loss: 1.2634657621383667\n",
      "Epoch 220/300, Training Loss: 1.2700022459030151, Validation Loss: 1.263450264930725\n",
      "Epoch 221/300, Training Loss: 1.2699958086013794, Validation Loss: 1.263435959815979\n",
      "Epoch 222/300, Training Loss: 1.2699896097183228, Validation Loss: 1.2634228467941284\n",
      "Epoch 223/300, Training Loss: 1.2699837684631348, Validation Loss: 1.2634106874465942\n",
      "Epoch 224/300, Training Loss: 1.2699782848358154, Validation Loss: 1.263399600982666\n",
      "Epoch 225/300, Training Loss: 1.2699731588363647, Validation Loss: 1.2633893489837646\n",
      "Epoch 226/300, Training Loss: 1.2699685096740723, Validation Loss: 1.2633806467056274\n",
      "Epoch 227/300, Training Loss: 1.2699638605117798, Validation Loss: 1.263372778892517\n",
      "Epoch 228/300, Training Loss: 1.269959807395935, Validation Loss: 1.2633657455444336\n",
      "Epoch 229/300, Training Loss: 1.269956111907959, Validation Loss: 1.2633594274520874\n",
      "Epoch 230/300, Training Loss: 1.2699522972106934, Validation Loss: 1.2633534669876099\n",
      "Epoch 231/300, Training Loss: 1.269948959350586, Validation Loss: 1.2633479833602905\n",
      "Epoch 232/300, Training Loss: 1.2699459791183472, Validation Loss: 1.2633423805236816\n",
      "Epoch 233/300, Training Loss: 1.2699432373046875, Validation Loss: 1.2633370161056519\n",
      "Epoch 234/300, Training Loss: 1.2699406147003174, Validation Loss: 1.263332486152649\n",
      "Epoch 235/300, Training Loss: 1.2699381113052368, Validation Loss: 1.2633284330368042\n",
      "Epoch 236/300, Training Loss: 1.2699358463287354, Validation Loss: 1.2633243799209595\n",
      "Epoch 237/300, Training Loss: 1.2699335813522339, Validation Loss: 1.2633204460144043\n",
      "Epoch 238/300, Training Loss: 1.269931674003601, Validation Loss: 1.26331627368927\n",
      "Epoch 239/300, Training Loss: 1.2699298858642578, Validation Loss: 1.2633122205734253\n",
      "Epoch 240/300, Training Loss: 1.2699280977249146, Validation Loss: 1.2633085250854492\n",
      "Epoch 241/300, Training Loss: 1.2699265480041504, Validation Loss: 1.2633053064346313\n",
      "Epoch 242/300, Training Loss: 1.2699251174926758, Validation Loss: 1.263301968574524\n",
      "Epoch 243/300, Training Loss: 1.2699235677719116, Validation Loss: 1.2632988691329956\n",
      "Epoch 244/300, Training Loss: 1.2699223756790161, Validation Loss: 1.2632958889007568\n",
      "Epoch 245/300, Training Loss: 1.269921064376831, Validation Loss: 1.2632932662963867\n",
      "Epoch 246/300, Training Loss: 1.269919753074646, Validation Loss: 1.2632907629013062\n",
      "Epoch 247/300, Training Loss: 1.2699187994003296, Validation Loss: 1.2632886171340942\n",
      "Epoch 248/300, Training Loss: 1.2699177265167236, Validation Loss: 1.2632865905761719\n",
      "Epoch 249/300, Training Loss: 1.2699164152145386, Validation Loss: 1.263284683227539\n",
      "Epoch 250/300, Training Loss: 1.2699154615402222, Validation Loss: 1.263283133506775\n",
      "Epoch 251/300, Training Loss: 1.2699146270751953, Validation Loss: 1.2632815837860107\n",
      "Epoch 252/300, Training Loss: 1.2699137926101685, Validation Loss: 1.2632802724838257\n",
      "Epoch 253/300, Training Loss: 1.2699129581451416, Validation Loss: 1.2632789611816406\n",
      "Epoch 254/300, Training Loss: 1.2699123620986938, Validation Loss: 1.2632774114608765\n",
      "Epoch 255/300, Training Loss: 1.269911527633667, Validation Loss: 1.2632758617401123\n",
      "Epoch 256/300, Training Loss: 1.2699108123779297, Validation Loss: 1.2632741928100586\n",
      "Epoch 257/300, Training Loss: 1.2699103355407715, Validation Loss: 1.2632726430892944\n",
      "Epoch 258/300, Training Loss: 1.2699095010757446, Validation Loss: 1.2632709741592407\n",
      "Epoch 259/300, Training Loss: 1.2699090242385864, Validation Loss: 1.2632699012756348\n",
      "Epoch 260/300, Training Loss: 1.2699085474014282, Validation Loss: 1.2632685899734497\n",
      "Epoch 261/300, Training Loss: 1.2699079513549805, Validation Loss: 1.2632670402526855\n",
      "Epoch 262/300, Training Loss: 1.2699073553085327, Validation Loss: 1.2632654905319214\n",
      "Epoch 263/300, Training Loss: 1.269906997680664, Validation Loss: 1.2632639408111572\n",
      "Epoch 264/300, Training Loss: 1.2699065208435059, Validation Loss: 1.2632625102996826\n",
      "Epoch 265/300, Training Loss: 1.269905924797058, Validation Loss: 1.263261318206787\n",
      "Epoch 266/300, Training Loss: 1.2699055671691895, Validation Loss: 1.263259768486023\n",
      "Epoch 267/300, Training Loss: 1.2699052095413208, Validation Loss: 1.2632582187652588\n",
      "Epoch 268/300, Training Loss: 1.2699049711227417, Validation Loss: 1.2632566690444946\n",
      "Early stopping at epoch 268\n",
      "Batch Size: 512\n",
      "Epochs: 300\n",
      "MSE: 1.2918057441711426\n",
      "RMSE: 1.1365762948989868\n",
      "Negative: \n",
      "13321\n",
      "Positive: \n",
      "5761\n",
      "Precision: 0.6980924431401321\n",
      "Recall: 1.0\n",
      "Precision@k: 0.755\n",
      "Recall@k: 0.056677426619623154\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Training Loss: 15.01095962524414, Validation Loss: 14.424958229064941\n",
      "Epoch 2/300, Training Loss: 14.337753295898438, Validation Loss: 13.86246109008789\n",
      "Epoch 3/300, Training Loss: 13.811692237854004, Validation Loss: 13.383710861206055\n",
      "Epoch 4/300, Training Loss: 13.360231399536133, Validation Loss: 12.906123161315918\n",
      "Epoch 5/300, Training Loss: 12.902227401733398, Validation Loss: 12.400491714477539\n",
      "Epoch 6/300, Training Loss: 12.407590866088867, Validation Loss: 11.854714393615723\n",
      "Epoch 7/300, Training Loss: 11.86825180053711, Validation Loss: 11.266538619995117\n",
      "Epoch 8/300, Training Loss: 11.282959938049316, Validation Loss: 10.63065242767334\n",
      "Epoch 9/300, Training Loss: 10.649086952209473, Validation Loss: 9.940839767456055\n",
      "Epoch 10/300, Training Loss: 9.964900970458984, Validation Loss: 9.2007474899292\n",
      "Epoch 11/300, Training Loss: 9.23444938659668, Validation Loss: 8.42455768585205\n",
      "Epoch 12/300, Training Loss: 8.469527244567871, Validation Loss: 7.627989768981934\n",
      "Epoch 13/300, Training Loss: 7.68568229675293, Validation Loss: 6.832998275756836\n",
      "Epoch 14/300, Training Loss: 6.905739784240723, Validation Loss: 6.06997537612915\n",
      "Epoch 15/300, Training Loss: 6.160520076751709, Validation Loss: 5.377790927886963\n",
      "Epoch 16/300, Training Loss: 5.490451812744141, Validation Loss: 4.8053717613220215\n",
      "Epoch 17/300, Training Loss: 4.9466633796691895, Validation Loss: 4.4090471267700195\n",
      "Epoch 18/300, Training Loss: 4.587741851806641, Validation Loss: 4.2394890785217285\n",
      "Epoch 19/300, Training Loss: 4.466631889343262, Validation Loss: 4.3116374015808105\n",
      "Epoch 20/300, Training Loss: 4.596463203430176, Validation Loss: 4.558040618896484\n",
      "Epoch 21/300, Training Loss: 4.901249885559082, Validation Loss: 4.822429656982422\n",
      "Epoch 22/300, Training Loss: 5.210958003997803, Validation Loss: 4.954023838043213\n",
      "Epoch 23/300, Training Loss: 5.364622592926025, Validation Loss: 4.906501770019531\n",
      "Epoch 24/300, Training Loss: 5.315279960632324, Validation Loss: 4.725228309631348\n",
      "Epoch 25/300, Training Loss: 5.113104820251465, Validation Loss: 4.484761714935303\n",
      "Epoch 26/300, Training Loss: 4.839742183685303, Validation Loss: 4.251851558685303\n",
      "Epoch 27/300, Training Loss: 4.568848133087158, Validation Loss: 4.069201946258545\n",
      "Epoch 28/300, Training Loss: 4.348175525665283, Validation Loss: 3.9532973766326904\n",
      "Epoch 29/300, Training Loss: 4.197634696960449, Validation Loss: 3.9008090496063232\n",
      "Epoch 30/300, Training Loss: 4.115413188934326, Validation Loss: 3.8964717388153076\n",
      "Epoch 31/300, Training Loss: 4.086691856384277, Validation Loss: 3.9208362102508545\n",
      "Epoch 32/300, Training Loss: 4.091713905334473, Validation Loss: 3.955367088317871\n",
      "Epoch 33/300, Training Loss: 4.111362457275391, Validation Loss: 3.9852402210235596\n",
      "Epoch 34/300, Training Loss: 4.13019323348999, Validation Loss: 4.000269412994385\n",
      "Epoch 35/300, Training Loss: 4.1374921798706055, Validation Loss: 3.9947545528411865\n",
      "Epoch 36/300, Training Loss: 4.12714958190918, Validation Loss: 3.966787338256836\n",
      "Epoch 37/300, Training Loss: 4.096983909606934, Validation Loss: 3.9174742698669434\n",
      "Epoch 38/300, Training Loss: 4.047893047332764, Validation Loss: 3.8501532077789307\n",
      "Epoch 39/300, Training Loss: 3.9831039905548096, Validation Loss: 3.769735813140869\n",
      "Epoch 40/300, Training Loss: 3.907405138015747, Validation Loss: 3.6820220947265625\n",
      "Epoch 41/300, Training Loss: 3.8264520168304443, Validation Loss: 3.5930190086364746\n",
      "Epoch 42/300, Training Loss: 3.746140480041504, Validation Loss: 3.5084238052368164\n",
      "Epoch 43/300, Training Loss: 3.6719295978546143, Validation Loss: 3.4331226348876953\n",
      "Epoch 44/300, Training Loss: 3.608078956604004, Validation Loss: 3.3703083992004395\n",
      "Epoch 45/300, Training Loss: 3.556892156600952, Validation Loss: 3.3206331729888916\n",
      "Epoch 46/300, Training Loss: 3.518322467803955, Validation Loss: 3.282533884048462\n",
      "Epoch 47/300, Training Loss: 3.4898762702941895, Validation Loss: 3.252566337585449\n",
      "Epoch 48/300, Training Loss: 3.466982126235962, Validation Loss: 3.225498914718628\n",
      "Epoch 49/300, Training Loss: 3.444139242172241, Validation Loss: 3.19665789604187\n",
      "Epoch 50/300, Training Loss: 3.4160709381103516, Validation Loss: 3.1626737117767334\n",
      "Epoch 51/300, Training Loss: 3.3794631958007812, Validation Loss: 3.1225674152374268\n",
      "Epoch 52/300, Training Loss: 3.333733081817627, Validation Loss: 3.0778262615203857\n",
      "Epoch 53/300, Training Loss: 3.2807936668395996, Validation Loss: 3.0314974784851074\n",
      "Epoch 54/300, Training Loss: 3.2243640422821045, Validation Loss: 2.986778974533081\n",
      "Epoch 55/300, Training Loss: 3.1684253215789795, Validation Loss: 2.9459073543548584\n",
      "Epoch 56/300, Training Loss: 3.115976095199585, Validation Loss: 2.909656047821045\n",
      "Epoch 57/300, Training Loss: 3.0684378147125244, Validation Loss: 2.877352714538574\n",
      "Epoch 58/300, Training Loss: 3.025602340698242, Validation Loss: 2.847348928451538\n",
      "Epoch 59/300, Training Loss: 2.986128330230713, Validation Loss: 2.81758713722229\n",
      "Epoch 60/300, Training Loss: 2.9481284618377686, Validation Loss: 2.7861616611480713\n",
      "Epoch 61/300, Training Loss: 2.909766674041748, Validation Loss: 2.7516896724700928\n",
      "Epoch 62/300, Training Loss: 2.8696389198303223, Validation Loss: 2.713489294052124\n",
      "Epoch 63/300, Training Loss: 2.8269896507263184, Validation Loss: 2.671618700027466\n",
      "Epoch 64/300, Training Loss: 2.781775712966919, Validation Loss: 2.626805305480957\n",
      "Epoch 65/300, Training Loss: 2.7345569133758545, Validation Loss: 2.5801517963409424\n",
      "Epoch 66/300, Training Loss: 2.6863510608673096, Validation Loss: 2.5329172611236572\n",
      "Epoch 67/300, Training Loss: 2.6381726264953613, Validation Loss: 2.4862418174743652\n",
      "Epoch 68/300, Training Loss: 2.590885877609253, Validation Loss: 2.440826177597046\n",
      "Epoch 69/300, Training Loss: 2.5449180603027344, Validation Loss: 2.396975040435791\n",
      "Epoch 70/300, Training Loss: 2.5002119541168213, Validation Loss: 2.3544576168060303\n",
      "Epoch 71/300, Training Loss: 2.456423759460449, Validation Loss: 2.312833070755005\n",
      "Epoch 72/300, Training Loss: 2.412978410720825, Validation Loss: 2.271620750427246\n",
      "Epoch 73/300, Training Loss: 2.3692996501922607, Validation Loss: 2.2304811477661133\n",
      "Epoch 74/300, Training Loss: 2.325009346008301, Validation Loss: 2.1893515586853027\n",
      "Epoch 75/300, Training Loss: 2.280031442642212, Validation Loss: 2.148408889770508\n",
      "Epoch 76/300, Training Loss: 2.2345974445343018, Validation Loss: 2.1079137325286865\n",
      "Epoch 77/300, Training Loss: 2.1892220973968506, Validation Loss: 2.0681562423706055\n",
      "Epoch 78/300, Training Loss: 2.144404172897339, Validation Loss: 2.0292887687683105\n",
      "Epoch 79/300, Training Loss: 2.100464344024658, Validation Loss: 1.9912996292114258\n",
      "Epoch 80/300, Training Loss: 2.0575926303863525, Validation Loss: 1.9540964365005493\n",
      "Epoch 81/300, Training Loss: 2.015738010406494, Validation Loss: 1.9174784421920776\n",
      "Epoch 82/300, Training Loss: 1.974759578704834, Validation Loss: 1.8812873363494873\n",
      "Epoch 83/300, Training Loss: 1.934561848640442, Validation Loss: 1.8454233407974243\n",
      "Epoch 84/300, Training Loss: 1.8950519561767578, Validation Loss: 1.809883952140808\n",
      "Epoch 85/300, Training Loss: 1.8562090396881104, Validation Loss: 1.7747646570205688\n",
      "Epoch 86/300, Training Loss: 1.818104863166809, Validation Loss: 1.7402451038360596\n",
      "Epoch 87/300, Training Loss: 1.7808936834335327, Validation Loss: 1.7065565586090088\n",
      "Epoch 88/300, Training Loss: 1.7447469234466553, Validation Loss: 1.6739392280578613\n",
      "Epoch 89/300, Training Loss: 1.7098554372787476, Validation Loss: 1.6426085233688354\n",
      "Epoch 90/300, Training Loss: 1.6763709783554077, Validation Loss: 1.6127285957336426\n",
      "Epoch 91/300, Training Loss: 1.6443674564361572, Validation Loss: 1.5843337774276733\n",
      "Epoch 92/300, Training Loss: 1.6138688325881958, Validation Loss: 1.5573912858963013\n",
      "Epoch 93/300, Training Loss: 1.584829330444336, Validation Loss: 1.531829595565796\n",
      "Epoch 94/300, Training Loss: 1.5571703910827637, Validation Loss: 1.5076172351837158\n",
      "Epoch 95/300, Training Loss: 1.5308502912521362, Validation Loss: 1.4847992658615112\n",
      "Epoch 96/300, Training Loss: 1.50594162940979, Validation Loss: 1.463545322418213\n",
      "Epoch 97/300, Training Loss: 1.4825530052185059, Validation Loss: 1.443660855293274\n",
      "Epoch 98/300, Training Loss: 1.4605515003204346, Validation Loss: 1.4252158403396606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m#loss = calculateLoss(task_loss, batch, num_nodes, batch.positional_encodings)\u001b[39;00m\n\u001b[0;32m    115\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 116\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    117\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    118\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch\u001b[38;5;241m.\u001b[39mnum_graphs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = list(range(data.edge_index.size(1)))\n",
    "import csv\n",
    "csv_filename = \"results.csv\"\n",
    "with open(csv_filename, mode='a', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"i\", \"Model\", \"Precision\", \"Recall\", \"Precision@k\", \"Recall@k\", \"MSE\"])  # Write header\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    #das hier klein, damit der Speicher nicht Ã¼berdreht wird. Aber nicht zu klein, weil sonst kommt es zu problemen!\n",
    "    if (i % 3 == 0):\n",
    "        train_indices, test_indices = train_test_split(indices, train_size=0.8, test_size=0.2)\n",
    "        train_indices, val_indices = train_test_split(train_indices, train_size=0.8, test_size=0.2, random_state=42)\n",
    "        np.savez('indices.npz', train_indices=train_indices, test_indices=test_indices, val_indices=val_indices)\n",
    "    # Now, you can comment out the above code that generates the indices\n",
    "    # Read the indices from the file\n",
    "    loaded_indices = np.load('indices.npz')\n",
    "    #irgendeine syntax\n",
    "    train_data = data.__class__()\n",
    "    test_data = data.__class__()\n",
    "    val_data = data.__class__()\n",
    "\n",
    "\n",
    "    #setzt die Parameter von train_data und test_data\n",
    "\n",
    "    #soweit ich es verstehe, sind alle 2.500 nodes im training und testset vorhanden. gesplittet werden nur die edges, d.h. \n",
    "    #es ist nur ein subset der 100.000 edges im training set sowie im test set vorhanden\n",
    "    # also 10% der Bewertungen \n",
    "    train_data.edge_index = data.edge_index[:, train_indices]\n",
    "    train_data.y = data.y[train_indices]\n",
    "    train_data.num_nodes = data.num_nodes\n",
    "    train_data.positional_encodings = data.positional_encodings\n",
    "    train_data.x = data.x\n",
    "\n",
    "\n",
    "    test_data.edge_index = data.edge_index[:, test_indices]\n",
    "    test_data.y = data.y[test_indices]\n",
    "    test_data.num_nodes = data.num_nodes\n",
    "    test_data.positional_encodings = data.positional_encodings\n",
    "    test_data.x = data.x\n",
    "\n",
    "\n",
    "    val_data.edge_index = data.edge_index[:, val_indices]\n",
    "    val_data.y = data.y[val_indices]\n",
    "    val_data.num_nodes = data.num_nodes\n",
    "    val_data.positional_encodings = data.positional_encodings\n",
    "    val_data.x = data.x\n",
    "        \n",
    "\n",
    "\n",
    "    # Step 6: Train and evaluate the GCN model\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Set the device --> aktiviere GPU falls vorhanden\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #------------------------------------------------------\n",
    "\n",
    "    #hidden channels und epochs tunen\n",
    "    hidden_channels=8 #8 und 16\n",
    "    lr = 0.01  #0.01 vs 0.001 \n",
    "    epochs = 300  #100 vs 200\n",
    "    batch_size = 512#512\n",
    "\n",
    "    #1, 16, 32 ,64, 128, 256, 512\n",
    "\n",
    "    #Early Stopping\n",
    "    patience = 40  # Number of epochs to wait for improvement\n",
    "    min_delta = 0.001  # Minimum improvement required to consider as improvement\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # this is for evaluation!\n",
    "    if (i % 3 == 0):\n",
    "        model = GCN_nopos(hidden_channels=hidden_channels)\n",
    "    elif (i % 3 == 1):\n",
    "        model = GCN_var1(hidden_channels=hidden_channels)\n",
    "    elif (i%3 == 2):\n",
    "        model = GCN_variant2(hidden_channels=hidden_channels)\n",
    "    #------------------------------------------------------\n",
    "    #loss function, and optimizer, MSE = Metrik fÃ¼r Loss \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Create data loaders for training and test sets\n",
    "    train_loader = DataLoader([train_data], batch_size=batch_size)\n",
    "    test_loader = DataLoader([test_data], batch_size=batch_size)\n",
    "    val_loader = DataLoader([val_data], batch_size=batch_size)\n",
    "\n",
    "    # Model training\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    predictions =[]\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model( batch.x.unsqueeze(1), batch.edge_index, batch.positional_encodings.unsqueeze(1))\n",
    "            task_loss = criterion(out, batch.y)\n",
    "            loss = task_loss\n",
    "            #loss = calculateLoss(task_loss, batch, num_nodes, batch.positional_encodings)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch.num_graphs\n",
    "            predictions = out.detach().cpu().numpy()\n",
    "            #print(predictions)\n",
    "\n",
    "        # Calculate average training loss\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            out= model(batch.x.unsqueeze(1),batch.edge_index, batch.positional_encodings.unsqueeze(1))\n",
    "            task_loss = criterion(out, batch.y)\n",
    "            loss = task_loss\n",
    "        # loss = calculateLoss(task_loss, batch, num_nodes, batch.positional_encodings)\n",
    "            \n",
    "            val_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Print training and validation loss for monitoring\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Set the model back to training mode\n",
    "        model.train()\n",
    "        '''\n",
    "        # Plotting training and validation curves\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        #plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Save the plot as an image file\n",
    "        plt.savefig('loss_plot.png')\n",
    "        '''\n",
    "\n",
    "        # Show the plot\n",
    "\n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x.unsqueeze(1), batch.edge_index, batch.positional_encodings.unsqueeze(1))\n",
    "            task_loss = criterion(out, batch.y)\n",
    "            test_loss = task_loss\n",
    "            #test_loss = calculateLoss(task_loss, batch, num_nodes, batch.positional_encodings)\n",
    "            \n",
    "            #print(f'Test Loss: {test_loss.item()}')\n",
    "            predictions.extend(out.cpu().numpy().flatten())\n",
    "            targets.extend(batch.y.cpu().numpy().flatten())\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "\n",
    "        rounded_predictions = np.round(predictions, decimals=0)  # Round the predicted ratings\n",
    "\n",
    "        # Plotting the distribution\n",
    "        plt.hist(rounded_predictions, bins=15, edgecolor='black')\n",
    "        plt.xlabel('Predicted Rating')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Distribution of Predicted Ratings')\n",
    "        plt.xticks(range(1, 16))\n",
    "        #plt.show()\n",
    "        plt.savefig('predicted_rankings.png')\n",
    "\n",
    "\n",
    "        mse = np.mean(np.abs(predictions - targets) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        k = 5  # Define the value of k\n",
    "\n",
    "        print(f\"Batch Size: {batch_size}\")\n",
    "        print(f\"Epochs: {epochs}\")\n",
    "        print   (f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        \n",
    "        threshold = 3.5 # Define the threshold to convert predictions into binary values\n",
    "        np.set_printoptions(threshold=sys.maxsize)  # Set the threshold to print the whole array\n",
    "\n",
    "        #print(rounded_predictions)\n",
    "        #print(predictions)\n",
    "\n",
    "        GAT_results = open(\"predictions_GAT.txt\", \"a\")\n",
    "\n",
    "        GAT_results.write(str(predictions))\n",
    "        \n",
    "        GAT_results.close()\n",
    "\n",
    "        precision_value = precision(predictions, targets, threshold)\n",
    "        recall_value = recall(predictions, targets, threshold)\n",
    "        precission_k, recall_k, normalized_recall_k = precission_recall_at_k(predictions, targets, 4, 1000)\n",
    "\n",
    "        with open(\"predictions.txt\", 'w') as file:\n",
    "            for prediction in predictions:\n",
    "                file.write(str(prediction) + '\\n')\n",
    "\n",
    "        print(f\"Precision: {precision_value}\")\n",
    "        print(f\"Recall: {recall_value}\")\n",
    "\n",
    "        \n",
    "        print(f\"Precision@k: {precission_k}\")\n",
    "        print(f\"Recall@k: {recall_k}\")\n",
    "        #print(f\"Normalized Recall@k: {normalized_recall_k}\")\n",
    "\n",
    "        #Now write the file! \n",
    "        if (i % 3 == 0):\n",
    "            model_name = \"GCN_nopos\"\n",
    "        elif (i % 3 == 1):\n",
    "            model_name = \"GCN_var1\"\n",
    "        elif (i%3 == 2):\n",
    "            model_name = \"GCN_variant2\"\n",
    "        \n",
    "        print(i)\n",
    "        with open(\"results.csv\", mode='a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([i, model_name, precision_value, recall_value, precission_k, recall_k, mse])\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047b8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
