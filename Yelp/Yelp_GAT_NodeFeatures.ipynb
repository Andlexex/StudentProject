{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43aec689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.utils as utils\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.nn import GINConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch_geometric as tg\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse as sp\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8122e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePosEncodings_rswe(edge_index, num_nodes):\n",
    "    edge_index = edge_index.t().tolist()\n",
    "    edges = [(src, dst) for src, dst in edge_index]\n",
    "    rows, cols = zip(*edges)\n",
    "    data = np.ones(len(rows))\n",
    "    A = csr_matrix((data, (rows, cols)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "    in_degrees_dict = {node: 0 for node in range(num_nodes)}\n",
    "    # Calculate the in-degrees for each node\n",
    "    for edge in edges:\n",
    "        _, dst = edge\n",
    "        in_degrees_dict[dst] += 1\n",
    "\n",
    "    in_degrees = np.array([in_degrees_dict[i] for i in range(len(in_degrees_dict))], dtype=float)\n",
    "    in_degrees = in_degrees.clip(1)  # Clip to ensure no division by zero\n",
    "    in_degrees = np.power(in_degrees, -1)  # Take the element-wise inverse square root\n",
    "\n",
    "    Dinv = sp.diags(in_degrees, dtype=float)\n",
    "\n",
    "    RW = A * Dinv  \n",
    "    M = RW\n",
    "    \n",
    "    # das ist wieder ein Hyperparameter; sollte >1 sein weil eins immer 0 ist irgendwie!\n",
    "    pos_enc_dim = 5\n",
    "\n",
    "    nb_pos_enc = pos_enc_dim\n",
    "    PE = [torch.from_numpy(M.diagonal()).float()]\n",
    "    M_power = M\n",
    "    for _ in range(nb_pos_enc-1):\n",
    "        M_power = M_power * M\n",
    "        PE.append(torch.from_numpy(M_power.diagonal()).float())\n",
    "    PE = torch.stack(PE,dim=-1)\n",
    "\n",
    "    #ERGEBNIS\n",
    "    RESULT_POS_ENCODING = PE \n",
    "    return RESULT_POS_ENCODING\n",
    "\n",
    "def calculatePosEncodings(edge_index, num_nodes):\n",
    "    print(\"checkpoint1\")\n",
    "    edge_index = edge_index.t().tolist()\n",
    "    edges = [(src, dst) for src, dst in edge_index]\n",
    "\n",
    "    # Create the adjacency matrix in CSR format -> das wird dann fÃ¼r die encodings benutzt!\n",
    "    rows, cols = zip(*edges)\n",
    "    data = np.ones(len(rows))\n",
    "    A = csr_matrix((data, (rows, cols)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "    ''' this code computes the in_degrees matrix from the edge list. it can later be adapted to compute the in-degrees matrix from the adjacency matrix (however, then, we should\n",
    "    do some tests with small sample graphs to ensure everytheing is correct\n",
    "    '''\n",
    "    in_degrees_dict = {node: 0 for node in range(num_nodes)}\n",
    "    # Calculate the in-degrees for each node\n",
    "    for edge in edges:\n",
    "        print(\"checkpoint2\")\n",
    "        _, dst = edge\n",
    "        in_degrees_dict[dst] += 1\n",
    "\n",
    "    in_degrees = np.array([in_degrees_dict[i] for i in range(len(in_degrees_dict))], dtype=float)\n",
    "    in_degrees = in_degrees.clip(1)  # Clip to ensure no division by zero\n",
    "    in_degrees = np.power(in_degrees, -0.5)  # Take the element-wise inverse square root\n",
    "    print(\"checkpoint3\")\n",
    "    # Create the sparse diagonal matrix N\n",
    "    N = sp.diags(in_degrees, dtype=float)\n",
    "\n",
    "    L = sp.eye(num_nodes) - N * A * N\n",
    "\n",
    "    #calc eigvals and eigVecs, equivalent to the original code\n",
    "    EigVal, EigVec = np.linalg.eig(L.toarray())\n",
    "    idx = EigVal.argsort() # increasing order\n",
    "    EigVal, EigVec = EigVal[idx], np.real(EigVec[:,idx])\n",
    "\n",
    "    #pos_enc_dim = hyperparameter!\n",
    "    pos_enc_dim = 5\n",
    "    RESULT_POS_ENCODING = torch.from_numpy(EigVec[:,1:pos_enc_dim+1]).float() \n",
    "    return RESULT_POS_ENCODING\n",
    "\n",
    "def calculateLoss(task_loss, batch, num_nodes, positional_encoding):\n",
    "    #HYPERPARAMETERS\n",
    "    device = \"cpu\"\n",
    "    pos_enc_dim = 1\n",
    "    alpha_loss: 1e-3\n",
    "    lambda_loss: 100  # ist auch 100\n",
    "\n",
    "    #edge_index im korrekten Format definieren\n",
    "    edge_index = batch.edge_index.t().tolist()\n",
    "    edge_index = [(src, dst) for src, dst in edge_index]\n",
    "\n",
    "    # Loss B: Laplacian Eigenvector Loss --------------------------------------------\n",
    "    n = num_nodes\n",
    "\n",
    "    # Laplacian \n",
    "    rows, cols = zip(*edge_index)\n",
    "    data = np.ones(len(rows))\n",
    "    A = csr_matrix((data, (rows, cols)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "    ''' this code computes the in_degrees matrix from the edge list. it can later be adapted to compute the in-degrees matrix from the adjacency matrix (however, then, we should\n",
    "    do some tests with small sample graphs to ensure everything is correct'''\n",
    "\n",
    "    in_degrees_dict = {node: 0 for node in range(num_nodes)}\n",
    "    # Calculate the in-degrees for each node\n",
    "    for edge in edge_index:\n",
    "        _, dst = edge\n",
    "        in_degrees_dict[dst] += 1\n",
    "\n",
    "    in_degrees = np.array([in_degrees_dict[i] for i in range(len(in_degrees_dict))], dtype=float)\n",
    "    in_degrees = in_degrees.clip(1)  # Clip to ensure no division by zero\n",
    "    in_degrees = np.power(in_degrees, -0.5)  # Take the element-wise inverse square root\n",
    "\n",
    "    # Create the sparse diagonal matrix N\n",
    "    N = sp.diags(in_degrees, dtype=float)\n",
    "    L = sp.eye(num_nodes) - N * A * N\n",
    "\n",
    "    p = positional_encoding\n",
    "    pT = torch.transpose(p, 1, 0)\n",
    "    loss_b_1 = torch.trace(torch.mm(torch.mm(pT, torch.Tensor(L.todense()).to(device)), p))\n",
    "\n",
    "    '''  TODO: loss_b_2 \n",
    "    '''\n",
    "\n",
    "    loss_b = loss_b_1\n",
    "\n",
    "    #TODO: parameter tunen!\n",
    "    loss = task_loss + 1e-3* loss_b\n",
    "    return loss\n",
    "\n",
    "\n",
    "def precision(predictions, targets, threshold):\n",
    "    # Apply a threshold to the predictions\n",
    "    binary_predictions = (predictions >= threshold).astype(int)\n",
    "    binary_targets = (targets >= threshold).astype(int)\n",
    "\n",
    "    # Calculate the true positive (TP) and false positive (FP) counts\n",
    "    TP = np.sum((binary_predictions == 1) & (binary_targets == 1))\n",
    "    FP = np.sum((binary_predictions == 1) & (binary_targets == 0))\n",
    "\n",
    "    print(\"Negative: \")\n",
    "    print(np.sum(binary_targets == 1))\n",
    "    print(\"Positive: \")\n",
    "    print(np.sum(binary_targets == 0))\n",
    "    # Calculate precision\n",
    "    precision_value = TP / (TP + FP)\n",
    "    return precision_value\n",
    "\n",
    "def recall(predictions, targets, threshold):\n",
    "    # Apply a threshold to the predictions\n",
    "    binary_predictions = (predictions >= threshold).astype(int)\n",
    "    binary_targets = (targets >= threshold).astype(int)\n",
    "    # Calculate the true positive (TP) and false negative (FN) counts\n",
    "    TP = np.sum((binary_predictions == 1) & (binary_targets == 1))\n",
    "    FN = np.sum((binary_predictions == 0) & (binary_targets == 1))\n",
    "    # Calculate recall\n",
    "    recall_value = TP / (TP + FN)\n",
    "    return recall_value\n",
    "\n",
    "def precission_recall_at_k (predictions, targets, threshold, k):\n",
    "    # Combine ratings and predictions into tuples for sorting\n",
    "    combined = list(zip(targets, predictions))\n",
    "\n",
    "    # Sort the combined list in descending order of predictions\n",
    "    combined.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract top k sorted items and calculate precision and recall\n",
    "    top_k_items = combined[:k]\n",
    "    true_positives = sum(1 for rating, _ in top_k_items if rating >= threshold)\n",
    "    false_positives = k - true_positives\n",
    "    relevant_items = sum(1 for rating in targets if rating >= threshold)\n",
    "    false_negatives = relevant_items - true_positives\n",
    "\n",
    "    precision_at_k = true_positives / (true_positives + false_positives)\n",
    "    recall_at_k = true_positives / (true_positives + false_negatives)\n",
    "    normalized_recall_at_k = recall_at_k / (k / relevant_items)\n",
    "\n",
    "\n",
    "    return precision_at_k, recall_at_k, normalized_recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4d17e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done business\n",
      "done reviews\n",
      "done users\n"
     ]
    }
   ],
   "source": [
    "# Reading in all the data\n",
    "\n",
    "business_ids=[]\n",
    "business_average_stars=[]\n",
    "business_review_count=[]\n",
    "\n",
    "try:\n",
    "    with open('yelp_dataset/yelp_academic_dataset_business.json', 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                business_ids.append(data[\"business_id\"])\n",
    "                business_average_stars.append(data[\"stars\"])\n",
    "                business_review_count.append(data[\"review_count\"])\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "print(\"done business\")\n",
    "\n",
    "review_ids=[]\n",
    "review_business_ids=[]\n",
    "review_user_ids=[]\n",
    "review_stars=[]\n",
    "\n",
    "try:\n",
    "    with open('yelp_dataset/yelp_academic_dataset_review.json', 'r', encoding='utf-8') as json_file:\n",
    "        for i,line in enumerate(json_file):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                review_ids.append(data[\"review_id\"])\n",
    "                review_business_ids.append(data[\"business_id\"])\n",
    "                review_user_ids.append(data[\"user_id\"])\n",
    "                review_stars.append(data[\"stars\"])\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "print(\"done reviews\")\n",
    "\n",
    "user_ids=[]\n",
    "\n",
    "try:\n",
    "    with open('yelp_dataset/yelp_academic_dataset_user.json', 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                user_ids.append(data[\"user_id\"])\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "print(\"done users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618b183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987897\n",
      "150346\n",
      "6990280\n",
      "---------------------------------------------\n",
      "20000\n",
      "10000\n",
      "6990280\n"
     ]
    }
   ],
   "source": [
    "# As there is too much data use a subset by manipulating the business and user sets\n",
    "\n",
    "print(len(user_ids))\n",
    "print(len(business_ids))\n",
    "print(len(review_stars))\n",
    "\n",
    "businesses = 10000\n",
    "users = 20000\n",
    "\n",
    "business_average_stars = business_average_stars[:businesses]\n",
    "business_review_count = business_review_count[:businesses]\n",
    "business_ids = business_ids[:businesses]\n",
    "\n",
    "user_ids = user_ids[:users]\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "print(len(user_ids))\n",
    "print(len(business_ids))\n",
    "print(len(review_stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed791a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47703\n"
     ]
    }
   ],
   "source": [
    "# User and business to index mapping in order.\n",
    "# Review lists are adjusted to only include users and businesses from the subset lists.\n",
    "\n",
    "user_to_index = {user_id: index for index, user_id in enumerate(set(user_ids))}\n",
    "business_to_index = {business_id: index for index, business_id in enumerate(set(business_ids))}\n",
    "\n",
    "\n",
    "user_index_col = [user_to_index[user_id] for user_id in user_ids]\n",
    "business_index_col = [business_to_index[business_id] for business_id in business_ids]\n",
    "\n",
    "skip_indexes = []\n",
    "current_index = -1\n",
    "\n",
    "for user_id in review_user_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        tmp = user_to_index[user_id]\n",
    "    except KeyError:\n",
    "        skip_indexes.append(current_index)\n",
    "\n",
    "current_index = -1\n",
    "for business_id in review_business_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        tmp = business_to_index[business_id]\n",
    "    except KeyError:\n",
    "        skip_indexes.append(current_index)    \n",
    "\n",
    "skip_indexes = set(skip_indexes)\n",
    "print(6990280 - len(skip_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d50b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22403\n",
      "30000\n",
      "Number of Users in index col 16327\n",
      "Number of businesses in index col 6076\n",
      "Total reviews left 47703\n",
      "22403\n"
     ]
    }
   ],
   "source": [
    "current_index = -1\n",
    "\n",
    "review_user_index_col = []\n",
    "for user_id in review_user_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        if current_index in skip_indexes:\n",
    "            pass\n",
    "        else:\n",
    "            user_index = user_to_index[user_id]\n",
    "            review_user_index_col.append(businesses+user_index)\n",
    "    except KeyError:\n",
    "        print(\"Huh?\")        \n",
    "        \n",
    "current_index = -1        \n",
    "review_business_index_col = []\n",
    "for business_id in review_business_ids:\n",
    "    try:\n",
    "        current_index = current_index + 1\n",
    "        if current_index in skip_indexes:\n",
    "            pass\n",
    "        else:\n",
    "            business_index = business_to_index[business_id]\n",
    "            review_business_index_col.append(business_index)\n",
    "    except KeyError:\n",
    "        print(\"Huh?\")\n",
    "    \n",
    "current_index = -1\n",
    "adjusted_review_stars = []\n",
    "for star in review_stars:\n",
    "        current_index = current_index + 1\n",
    "        if current_index in skip_indexes:\n",
    "            pass\n",
    "        else:\n",
    "            adjusted_review_stars.append(star)\n",
    "\n",
    "num_nodes = len(set(review_user_index_col)) + len(set(review_business_index_col)) \n",
    "print(num_nodes)\n",
    "print(len(user_to_index)+len(business_to_index))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of Users in index col \" + str(len(set(review_user_index_col))))\n",
    "print(\"Number of businesses in index col \" + str(len(set(review_business_index_col))))\n",
    "print(\"Total reviews left \" + str(len(adjusted_review_stars)))\n",
    "print(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f84a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4554\n",
      "tensor([[5.0000e+00, 1.5371e-03],\n",
      "        [3.0000e+00, 3.2938e-03],\n",
      "        [3.5000e+00, 4.8309e-03],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Feature list including average stars and the review_count/max_review_count of a business.\n",
    "# Also a dummy padding is added for the users.\n",
    "\n",
    "adjusted_features = []\n",
    "\n",
    "for starts in business_average_stars:\n",
    "    adjusted_features.append([starts])\n",
    "    \n",
    "highest_review_count = 0\n",
    "for review in business_review_count:\n",
    "    if(review > highest_review_count):\n",
    "        highest_review_count = review\n",
    "print(highest_review_count)\n",
    "        \n",
    "for i in range(len(business_review_count)):\n",
    "    adjusted_features[i].append(business_review_count[i]/highest_review_count)\n",
    "\n",
    "adjusted_features_tensor = torch.tensor(adjusted_features)\n",
    "\n",
    "num_features = len(adjusted_features[0])\n",
    "\n",
    "num_users = len(set(user_ids))\n",
    "user_genre_features = torch.zeros(num_users,num_features)\n",
    "\n",
    "features = torch.cat((adjusted_features_tensor, user_genre_features), dim=0)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a582bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21258, 15822, 23997,  ..., 21154, 20620, 25435],\n",
      "        [ 4947,  9085,  5907,  ...,  2317,  4137,   164]])\n"
     ]
    }
   ],
   "source": [
    "rating_tensor = torch.tensor(adjusted_review_stars, dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([review_user_index_col, review_business_index_col], dtype=torch.long)\n",
    "\n",
    "positional_encodings = calculatePosEncodings_rswe(edge_index, 30000)\n",
    "\n",
    "#TODO: num nodes 30.000 oder num_nodes?\n",
    "data = Data(edge_index=edge_index, x=features, y=rating_tensor, positional_encodings=positional_encodings)\n",
    "\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f393a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel_nopos(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GATModel_nopos, self).__init__()\n",
    "\n",
    "        # number of in layers = number of node features + number of positional embedding dimensions\n",
    "        num_features = 7\n",
    "        self.conv1 = GATv2Conv(num_features, hidden_channels, 1, edge_dim=1)\n",
    "        self.conv1_nopos = GATv2Conv(2, hidden_channels, 1, edge_dim=1)\n",
    "\n",
    "        self.conv2 = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "        self.conv2_var2 = GATv2Conv(hidden_channels*2, hidden_channels, 1)\n",
    "        self.conv3 = GATv2Conv(hidden_channels, 1, 1)\n",
    "\n",
    "        #this is for learning of the positional encodings, which is seperate!!!\n",
    "        self.conv1_pos = GATv2Conv(5, hidden_channels, 1)\n",
    "        self.conv2_pos = GATv2Conv(hidden_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, pos_embeddings):\n",
    "        x = x.view(-1, x.size(2))\n",
    "        #pos_embeddings = pos_embeddings.view(-1, pos_embeddings.size(2))        \n",
    "        #x = torch.cat([x, pos_embeddings], dim=1)\n",
    "\n",
    "        #fh from the paper\n",
    "        #eigentlich mÃ¼sste man die edge features direkt reinfÃ¼ttern kÃ¶nnen: so         x = self.conv1(x, edge_index,edge_attr=edge_attr)\n",
    "        x = self.conv1_nopos(x, edge_index) #, # edge_attr = edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        #these are the user features (right now: none)\n",
    "        user_embed = x[edge_index[0]]\n",
    "        #these are the movie features\n",
    "        movie_embed = x[edge_index[1]]\n",
    "\n",
    "        #ratings = torch.sum(user_embed * movie_embed, dim=1)\n",
    "        ratings = torch.sum(movie_embed, dim=1)\n",
    "        return ratings, pos_embeddings\n",
    "    \n",
    "class GATModel_variant1(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GATModel_variant1, self).__init__()\n",
    "\n",
    "        # number of in layers = number of node features + number of positional embedding dimensions\n",
    "        num_features = 7\n",
    "        self.conv1 = GATv2Conv(num_features, hidden_channels, 1, edge_dim=1)\n",
    "        self.conv2 = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "        self.conv3 = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "\n",
    "        #this is for learning of the positional encodings, which is seperate!!!\n",
    "        self.conv1_pos = GATv2Conv(5, hidden_channels, 1)\n",
    "        self.conv2_pos = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "        self.conv3_pos = GATv2Conv(hidden_channels, hidden_channels,1)\n",
    "        self.linear = nn.Linear(hidden_channels, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, pos_embeddings):\n",
    "        x = x.view(-1, x.size(2))\n",
    "        pos_embeddings = pos_embeddings.view(-1, pos_embeddings.size(2))      \n",
    "        x = torch.cat([x, pos_embeddings], dim=1)\n",
    "\n",
    "        #fh from the paper\n",
    "        #eigentlich mÃ¼sste man die edge features direkt reinfÃ¼ttern kÃ¶nnen: so         x = self.conv1(x, edge_index,edge_attr=edge_attr)\n",
    "        x = self.conv1(x, edge_index) #, # edge_attr = edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        #Now the learning of positional embeddings. So this is fp from the paper\n",
    "        pos_embeddings = self.conv1_pos(pos_embeddings, edge_index)\n",
    "        pos_embeddings = F.relu(pos_embeddings)\n",
    "        pos_embeddings = self.conv2_pos(pos_embeddings, edge_index)\n",
    "        pos_embeddings = F.relu(pos_embeddings)\n",
    "        pos_embeddings = self.conv3_pos(pos_embeddings, edge_index)\n",
    "\n",
    "        final_output = self.linear(torch.cat([x, pos_embeddings]))\n",
    "        #these are the movie features\n",
    "        movie_embed = final_output[edge_index[1]]            \n",
    "\n",
    "        #ratings = torch.sum(user_embed * movie_embed, dim=1)\n",
    "        ratings = torch.sum(movie_embed, dim=1)\n",
    "        return ratings, pos_embeddings\n",
    "    \n",
    "class GATModel_variant2(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GATModel_variant2, self).__init__()\n",
    "\n",
    "        # number of in layers = number of node features + number of positional embedding dimensions\n",
    "        num_features = 7\n",
    "        self.conv1 = GATv2Conv(num_features, hidden_channels, 1, edge_dim=1)\n",
    "        self.conv1_nopos = GATv2Conv(2, hidden_channels, 1, edge_dim=1)\n",
    "        self.conv2 = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "        self.conv2_var2 = GATv2Conv(hidden_channels*2, hidden_channels, 1)\n",
    "        self.conv3 = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "\n",
    "        #this is for learning of the positional encodings, which is seperate!!!\n",
    "        self.conv1_pos = GATv2Conv(5, hidden_channels, 1)\n",
    "        self.conv2_pos = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "        self.conv3_pos = GATv2Conv(hidden_channels, hidden_channels, 1)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, pos_embeddings):\n",
    "        x = x.view(-1, x.size(2))\n",
    "        pos_embeddings = pos_embeddings.view(-1, pos_embeddings.size(2))        \n",
    "        x = torch.cat([x, pos_embeddings], dim=1)\n",
    "\n",
    "        #fh from the paper\n",
    "        #eigentlich mÃ¼sste man die edge features direkt reinfÃ¼ttern kÃ¶nnen: so         x = self.conv1(x, edge_index,edge_attr=edge_attr)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        pos_embeddings = self.conv1_pos(pos_embeddings, edge_index)\n",
    "        pos_embeddings = F.relu(pos_embeddings)\n",
    "        #x = self.conv2(torch.cat([x,pos_embeddings],dim=1), edge_index)\n",
    "        x = self.conv2_var2(torch.cat([x,pos_embeddings],dim=1), edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        movie_embed = x[edge_index[1]]\n",
    "        ratings = torch.sum(movie_embed, dim=1)\n",
    "\n",
    "        return ratings, pos_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95e32818",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (30000x2 and 19x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vadym\\Desktop\\Forschungsprojekt\\Yelp\\yelp_dataset_jsons\\Yelp_GAT_NodeFeatures.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)        \n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m     out, batch\u001b[39m.\u001b[39mpositional_encodings \u001b[39m=\u001b[39m model( batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m), batch\u001b[39m.\u001b[39;49medge_index, batch\u001b[39m.\u001b[39;49mpositional_encodings\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m     task_loss \u001b[39m=\u001b[39m criterion(out, batch\u001b[39m.\u001b[39my)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m     loss \u001b[39m=\u001b[39m task_loss\n",
      "File \u001b[1;32mc:\\Users\\Vadym\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Vadym\\Desktop\\Forschungsprojekt\\Yelp\\yelp_dataset_jsons\\Yelp_GAT_NodeFeatures.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, x\u001b[39m.\u001b[39msize(\u001b[39m2\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#pos_embeddings = pos_embeddings.view(-1, pos_embeddings.size(2))        \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#x = torch.cat([x, pos_embeddings], dim=1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#fh from the paper\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#eigentlich mÃ¼sste man die edge features direkt reinfÃ¼ttern kÃ¶nnen: so         x = self.conv1(x, edge_index,edge_attr=edge_attr)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1_nopos(x, edge_index) \u001b[39m#, # edge_attr = edge_attr)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vadym/Desktop/Forschungsprojekt/Yelp/yelp_dataset_jsons/Yelp_GAT_NodeFeatures.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\Vadym\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Vadym\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:215\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, Tensor):\n\u001b[0;32m    214\u001b[0m     \u001b[39massert\u001b[39;00m x\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m--> 215\u001b[0m     x_l \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin_l(x)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, H, C)\n\u001b[0;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_weights:\n\u001b[0;32m    217\u001b[0m         x_r \u001b[39m=\u001b[39m x_l\n",
      "File \u001b[1;32mc:\\Users\\Vadym\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Vadym\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:132\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (30000x2 and 19x256)"
     ]
    }
   ],
   "source": [
    "indices = list(range(data.edge_index.size(1)))\n",
    "import csv\n",
    "\n",
    "csv_filename = \"GAT_results.csv\"\n",
    "with open(csv_filename, mode='a', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"i\", \"Model\", \"Precision\", \"Recall\", \"Precision@k\", \"Recall@k\", \"MSE\"])  # Write header\n",
    "\n",
    "for i in range(30):\n",
    "    if (i % 3 == 0):\n",
    "        train_indices, test_indices = train_test_split(indices, train_size=0.8, test_size=0.2)\n",
    "        train_indices, val_indices = train_test_split(train_indices, train_size=0.8, test_size=0.2, random_state=42)\n",
    "        np.savez('indices.npz', train_indices=train_indices, test_indices=test_indices, val_indices=val_indices)\n",
    "\n",
    "    loaded_indices = np.load('indices.npz')\n",
    "    train_indices = loaded_indices['train_indices']\n",
    "    test_indices = loaded_indices['test_indices']\n",
    "    val_indices = loaded_indices['val_indices']\n",
    "\n",
    "    #irgendeine syntax\n",
    "    train_data = data.__class__()\n",
    "    test_data = data.__class__()\n",
    "    val_data = data.__class__()\n",
    "\n",
    "    #setzt die Parameter von train_data und test_data\n",
    "    #soweit ich es verstehe, sind alle 2.500 nodes im training und testset vorhanden. gesplittet werden nur die edges, d.h. \n",
    "    #es ist nur ein subset der 100.000 edges im training set sowie im test set vorhanden\n",
    "    # also 10% der Bewertungen \n",
    "    train_data.edge_index = data.edge_index[:, train_indices]\n",
    "    train_data.y = rating_tensor[train_indices] #muss so sein, weil indicies sich auf original tensor beziehen!\n",
    "    train_data.num_nodes = data.num_nodes\n",
    "    train_data.positional_encodings = data.positional_encodings\n",
    "    train_data.x = data.x\n",
    "\n",
    "    test_data.edge_index = data.edge_index[:, test_indices]\n",
    "    test_data.y = rating_tensor[test_indices]\n",
    "    test_data.num_nodes = data.num_nodes\n",
    "    test_data.positional_encodings = data.positional_encodings\n",
    "    test_data.x = data.x\n",
    "\n",
    "\n",
    "    val_data.edge_index = data.edge_index[:, val_indices]\n",
    "    val_data.y = rating_tensor[val_indices]\n",
    "    val_data.num_nodes = data.num_nodes\n",
    "    val_data.positional_encodings = data.positional_encodings\n",
    "    val_data.x = data.x\n",
    "\n",
    "\n",
    "\n",
    "    # Step 6: Train and evaluate the GCN model\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Set the device --> aktiviere GPU falls vorhanden\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #------------------------------------------------------\n",
    "\n",
    "    #hidden channels und epochs tunen\n",
    "    hidden_channels= 256 #war 256\n",
    "    lr = 0.01  #0.01 vs 0.001 \n",
    "    epochs = 150  #100 vs 200\n",
    "    batch_size = 512#512\n",
    "\n",
    "    #1, 16, 32 ,64, 128, 256, 512\n",
    "\n",
    "    #Early Stopping\n",
    "    patience = 30  # Number of epochs to wait for improvement\n",
    "    min_delta = 0.001  # Minimum improvement required to consider as improvement\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    if (i % 3 == 0):\n",
    "        model = GATModel_nopos(hidden_channels=hidden_channels)\n",
    "    elif (i % 3 == 1):\n",
    "        model = GATModel_variant1(hidden_channels=hidden_channels)\n",
    "    elif (i%3 == 2):\n",
    "        model = GATModel_variant2(hidden_channels=hidden_channels)\n",
    "\n",
    "\n",
    "    #------------------------------------------------------\n",
    "    #------------------------------------------------------\n",
    "    #loss function, and optimizer, MSE = Metrik fÃ¼r Loss \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Create data loaders for training and test sets\n",
    "    train_loader = DataLoader([train_data], batch_size=batch_size)\n",
    "    test_loader = DataLoader([test_data], batch_size=batch_size)\n",
    "    val_loader = DataLoader([val_data], batch_size=batch_size)\n",
    "\n",
    "    # Model training\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    predictions =[]\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)        \n",
    "            out, batch.positional_encodings = model( batch.x.unsqueeze(1), batch.edge_index, batch.positional_encodings.unsqueeze(1))\n",
    "            task_loss = criterion(out, batch.y)\n",
    "            loss = task_loss\n",
    "            #loss = calculateLoss(task_loss, batch, num_nodes, batch.positional_encodings)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch.num_graphs\n",
    "            predictions = out.detach().cpu().numpy()\n",
    "            #print(predictions)\n",
    "\n",
    "        # Calculate average training loss\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            out, batch.positional_encodings = model(batch.x.unsqueeze(1),batch.edge_index, batch.positional_encodings.unsqueeze(1))\n",
    "            task_loss = criterion(out, batch.y)\n",
    "            loss = task_loss\n",
    "            #loss = calculateLoss(task_loss, batch, num_nodes, batch.positional_encodings)\n",
    "            \n",
    "            val_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Print training and validation loss for monitoring\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Set the model back to training mode\n",
    "        model.train()\n",
    "    '''\n",
    "    # Plotting training and validation curves\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    #plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot as an image file\n",
    "    plt.savefig('loss_plot.png')\n",
    "    '''\n",
    "\n",
    "    # Show the plot\n",
    "\n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        targets = []\n",
    "\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out, batch.positional_encodings = model(batch.x.unsqueeze(1), batch.edge_index, batch.positional_encodings.unsqueeze(1))\n",
    "            task_loss = criterion(out, batch.y)\n",
    "            test_loss = task_loss\n",
    "            #test_loss = calculateLoss(task_loss, batch, num_nodes, batch.positional_encodings)\n",
    "            \n",
    "            #print(f'Test Loss: {test_loss.item()}')\n",
    "            predictions.extend(out.cpu().numpy().flatten())\n",
    "            targets.extend(batch.y.cpu().numpy().flatten())\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "\n",
    "        rounded_predictions = np.round(predictions, decimals=0)  # Round the predicted ratings\n",
    "\n",
    "        # Plotting the distribution\n",
    "        plt.hist(rounded_predictions, bins=15, edgecolor='black')\n",
    "        plt.xlabel('Predicted Rating')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Distribution of Predicted Ratings')\n",
    "        plt.xticks(range(1, 16))\n",
    "        #plt.show()\n",
    "        plt.savefig('predicted_rankings.png')\n",
    "\n",
    "\n",
    "        mse = np.mean(np.abs(predictions - targets) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        k = 10  # Define the value of k\n",
    "\n",
    "        print(f\"Batch Size: {batch_size}\")\n",
    "        print(f\"Epochs: {epochs}\")\n",
    "        print   (f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        \n",
    "        threshold = 3.5 # Define the threshold to convert predictions into binary values\n",
    "        np.set_printoptions(threshold=sys.maxsize)  # Set the threshold to print the whole array\n",
    "\n",
    "        #print(rounded_predictions)\n",
    "        #print(predictions)\n",
    "\n",
    "        GAT_results = open(\"predictions_GAT.txt\", \"a\")\n",
    "        GAT_results.write(str(predictions))\n",
    "        GAT_results.close()\n",
    "\n",
    "        precision_value = precision(predictions, targets, threshold)\n",
    "        recall_value = recall(predictions, targets, threshold)\n",
    "\n",
    "        precission_k, recall_k, normalized_recall_k = precission_recall_at_k(predictions, targets, 4, 50)\n",
    "\n",
    "        with open(\"predictions.txt\", 'w') as file:\n",
    "            for prediction in predictions:\n",
    "                file.write(str(prediction) + '\\n')\n",
    "\n",
    "        print(f\"Precision: {precision_value}\")\n",
    "        print(f\"Recall: {recall_value}\")\n",
    "\n",
    "        print(f\"Precision@k: {precission_k}\")\n",
    "        print(f\"Recall@k: {recall_k}\")\n",
    "\n",
    "         #Now write the file! \n",
    "        if (i % 3 == 0):\n",
    "            model_name = \"GAN_nopos\"\n",
    "        elif (i % 3 == 1):\n",
    "            model_name = \"GAN_var1\"\n",
    "        elif (i%3 == 2):\n",
    "            model_name = \"GAN_variant2\"\n",
    "\n",
    "\n",
    "        with open(csv_filename, mode='a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([i, model_name, precision_value, recall_value, precission_k, recall_k, mse])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047b8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
